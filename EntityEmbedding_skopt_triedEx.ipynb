{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8931,
     "status": "ok",
     "timestamp": 1567061395658,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "xL0i5es-0xkL",
    "outputId": "0408ba24-b4e4-410f-a87b-e3bb960af4ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/44/60f82c97d1caa98752c7da2c1681cab5c7a390a0fdd3a55fac672b321cac/scikit_optimize-0.5.2-py2.py3-none-any.whl (74kB)\n",
      "\r",
      "\u001b[K     |████▍                           | 10kB 16.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 20kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 30kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 40kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 51kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 61kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 71kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 81kB 7.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->scikit-optimize) (0.13.2)\n",
      "Installing collected packages: scikit-optimize\n",
      "Successfully installed scikit-optimize-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AylZWiR08PZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "import os\n",
    "os.chdir(\"/gdrive/My Drive/Colab Notebooks/dacon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_KSBg3g0-J6"
   },
   "outputs": [],
   "source": [
    "resampled = pd.read_csv('./data/resampled_0825.csv',parse_dates=['date'])\n",
    "resampled.drop('holiday',axis=1,inplace=True)\n",
    "resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47948,
     "status": "ok",
     "timestamp": 1566974875473,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "Ors_E01N1E24",
    "outputId": "b34f46c3-ab46-4ac9-a9db-bc5ce0a7e3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1841687, 119)\n",
      "(1841687, 121)\n"
     ]
    }
   ],
   "source": [
    "naive_store_info = pd.read_csv('data/comp_9th/naive_store_info.csv')\n",
    "naive_store_info = naive_store_info[['store_id','type_bus','high_region']]\n",
    "print(resampled.shape)\n",
    "resampled = resampled.merge(naive_store_info, on=['store_id'])\n",
    "print(resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7NM0ISl6brN"
   },
   "outputs": [],
   "source": [
    "# resampled['cycle_idx_week1'] = (resampled['store_id'].astype(int).astype(str)) + (resampled['cycle_idx_week1'].astype(int).astype(str))\n",
    "# resampled['cycle_idx_week4'] = (resampled['store_id'].astype(int).astype(str)) + (resampled['cycle_idx_week4'].astype(int).astype(str))\n",
    "# resampled['cycle_idx_week8'] = (resampled['store_id'].astype(int).astype(str)) + (resampled['cycle_idx_week8'].astype(int).astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qiKXaClBxjO4"
   },
   "outputs": [],
   "source": [
    "# resampled.drop(['cycle_idx_week1', 'cycle_idx_week4','cycle_idx_week8'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DghMUcS7zVye"
   },
   "outputs": [],
   "source": [
    "target = 'y'\n",
    "cat_vars = ['store_id',  'Month', 'Week', 'Day', 'Dayofweek','Dayofyear',\n",
    "            'weekofyear', 'type_bus', 'high_region','hday_name','is_holiday',\n",
    "            'is_weekend','cur_zero','cycle_idx_week1', 'cycle_idx_week4', 'cycle_idx_week8']\n",
    "\n",
    "cont_vars = [cols for cols in resampled.columns.values if cols not in cat_vars+[target,'date']]\n",
    "\n",
    "ratios = [i for i in cont_vars if \"ratio\" in i]\n",
    "non_ratios = [i for i in cont_vars if i not in ratios]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZynVEm9KBSIY"
   },
   "outputs": [],
   "source": [
    "resampled[ratios] = resampled[ratios].replace(np.inf, 1e+17)\n",
    "resampled[ratios] = resampled[ratios].replace(-np.inf, -1e+17)\n",
    "resampled[non_ratios] = resampled[non_ratios].fillna(value=-1)\n",
    "resampled[ratios] = resampled[ratios].fillna(value=0)\n",
    "print(resampled[cont_vars].columns[resampled[cont_vars].isna().any()].tolist())\n",
    "\n",
    "resampled = resampled.set_index('date')\n",
    "resampled[cat_vars] = resampled[cat_vars].fillna(value='NaN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6293,
     "status": "ok",
     "timestamp": 1566975767833,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "9k30yb7k1G6l",
    "outputId": "29d102c9-8be0-48e4-a472-171b3b6bebce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1841687, 120)\n"
     ]
    }
   ],
   "source": [
    "print(resampled.shape)\n",
    "\n",
    "resampled['type_bus'] = resampled['type_bus'].astype(str)\n",
    "resampled['high_region'] = resampled['high_region'].astype(str)\n",
    "\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "encoders = {}\n",
    "for v in cat_vars:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(resampled[v].values)\n",
    "    encoders[v] = le\n",
    "    resampled.loc[:, v] = le.transform(resampled[v].values)\n",
    "    #print('{0}: {1}'.format(v, le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3227,
     "status": "ok",
     "timestamp": 1566975776105,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "3PZX-0Rl1K1s",
    "outputId": "d6888477-db3d-4256-8978-f26f926dc9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1639086, 120)\n",
      "(1144174, 120)\n",
      "(23604, 120)\n",
      "(23448, 120)\n"
     ]
    }
   ],
   "source": [
    "d = [i.date() for i in pd.date_range('2017-01-01', '2018-10-31')]\n",
    "import random\n",
    "random.seed(2019)\n",
    "idx = random.sample(d, 5)\n",
    "\n",
    "train = resampled[(resampled.index <= pd.to_datetime('2018-11-22')) & \n",
    "                    (~resampled.index.isin(idx))]\n",
    "val  = resampled[((resampled.index <= pd.to_datetime('2018-11-29')) &\n",
    "                 (resampled.index  >= pd.to_datetime('2018-11-23'))) |\n",
    "                 (resampled.index.isin(idx))]\n",
    "real_test = resampled[resampled.index  == pd.to_datetime('2019-02-28')]\n",
    "\n",
    "print(train.shape)\n",
    "train = train[train.y > 0]\n",
    "train = train[train.amount > 0]\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "val = val[val.y > 0]\n",
    "print(val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-PPUyff1Mvp"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = train[cat_vars + cont_vars].copy()\n",
    "X_val = val[cat_vars + cont_vars].copy()\n",
    "y = train[target].copy()\n",
    "y_val = val[target].copy()\n",
    "\n",
    "X_test = real_test[cat_vars + cont_vars].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, cont_vars] = scaler.fit_transform(X[cont_vars].values)\n",
    "X_val.loc[:, cont_vars] = scaler.transform(X_val[cont_vars].values)\n",
    "X_test.loc[:, cont_vars] = scaler.transform(X_test[cont_vars].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12292,
     "status": "ok",
     "timestamp": 1566975807729,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "KZU1SBKUj8XV",
    "outputId": "e149c00f-75a8-4e95-ce24-f0aef7007e97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihGh9iPg1P8O"
   },
   "outputs": [],
   "source": [
    "for v in cat_vars:\n",
    "    X[v] = X[v].astype('int').astype('category').cat.as_ordered()\n",
    "    X_val[v] = X_val[v].astype('int').astype('category').cat.as_ordered()\n",
    "    X_test[v] = X_test[v].astype('int').astype('category').cat.as_ordered()\n",
    "\n",
    "for v in cont_vars:\n",
    "    X[v] = X[v].astype('float32')\n",
    "    X_val[v] = X_val[v].astype('float32')\n",
    "    X_test[v] = X_test[v].astype('float32')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15042,
     "status": "ok",
     "timestamp": 1566975830895,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "ZyAd7ECI1SlL",
    "outputId": "6ce8b72f-aba1-4451-ad87-806eb5d435c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1967, 64),\n",
       " (12, 6),\n",
       " (52, 26),\n",
       " (31, 16),\n",
       " (7, 4),\n",
       " (366, 64),\n",
       " (52, 26),\n",
       " (40, 20),\n",
       " (18, 9),\n",
       " (20, 10),\n",
       " (2, 1),\n",
       " (2, 1),\n",
       " (1, 1),\n",
       " (47, 24),\n",
       " (14, 7),\n",
       " (6, 3)]"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_sizes = [(c, len(X[c].cat.categories)) for c in cat_vars]\n",
    "cat_sizes\n",
    "\n",
    "embedding_sizes = [(c, min(64, (c + 1) // 2)) for _, c in cat_sizes ]\n",
    "#embedding_sizes = [(c, min(50, (c + 1) // 2)) for _, c in cat_sizes ]\n",
    "embedding_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1660,
     "status": "ok",
     "timestamp": 1566975841443,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "op0zBaEN1Umg",
    "outputId": "d15479ab-7237-44b4-f9ce-9e73da57efa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17, 17)"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array = []\n",
    "X_val_array = []\n",
    "X_test_array = []\n",
    "\n",
    "for i, v in enumerate(cat_vars):\n",
    "    X_array.append(X.iloc[:, i])\n",
    "    X_val_array.append(X_val.iloc[:, i])\n",
    "    X_test_array.append(X_test.iloc[:, i])\n",
    "\n",
    "X_array.append(X.iloc[:, len(cat_vars):])\n",
    "X_val_array.append(X_val.iloc[:, len(cat_vars):])\n",
    "X_test_array.append(X_test.iloc[:, len(cat_vars):])\n",
    "\n",
    "len(X_array), len(X_val_array), len(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1566975848286,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "xynJ9nBr1XWZ",
    "outputId": "2f024f6d-6d63-4c8b-eeef-e9d2f5cbf6f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entity Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yRhn2uN1WyB"
   },
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, BatchNormalization, Concatenate\n",
    "from keras.layers import Dropout, Dense, Input, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.regularizers import l2, l1\n",
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1566978246495,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "yazUAAhc1ZgX",
    "outputId": "54313eec-8221-476f-a0bd-86651b7452dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrEDlFy81bLZ"
   },
   "outputs": [],
   "source": [
    "def EmbeddingNet(cat_vars, cont_vars, embedding_sizes, learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, dr_rate):\n",
    "    inputs = []\n",
    "    embed_layers = []\n",
    "    for (c, (in_size, out_size)) in zip(cat_vars, embedding_sizes):\n",
    "        i = Input(shape=(1,))\n",
    "        o = Embedding(in_size, out_size, name=c)(i)\n",
    "        o = Reshape(target_shape=(out_size,))(o)\n",
    "        inputs.append(i)\n",
    "        embed_layers.append(o)\n",
    "\n",
    "\n",
    "    embed = Concatenate()(embed_layers)\n",
    "    embed = Dropout(dr_rate)(embed)\n",
    "\n",
    "    cont_input = Input(shape=(len(cont_vars),))\n",
    "    inputs.append(cont_input)\n",
    "\n",
    "    x = Concatenate()([embed, cont_input])\n",
    "\n",
    "    for i in range(num_dense_layers):\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "        x = Dense(int(num_dense_nodes / (2**(i))) ,\n",
    "                  kernel_initializer='he_normal')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(dr_rate)(x)\n",
    "\n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('linear')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-Yk1Mbk1fHQ"
   },
   "outputs": [],
   "source": [
    "from CLR.clr_callback import CyclicLR\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "dim_learning_rate = Real(low=1e-5, high=1e-3, prior='log-uniform', \n",
    "                         name='learning_rate')                           # 0.00005\n",
    "dim_num_dense_layers = Integer(low=2, high=4, name='num_dense_layers')   # 3\n",
    "dim_num_dense_nodes = Integer(low=500, high=1024, name='num_dense_nodes')# 512\n",
    "dim_dr_rate = Real(low=0.05, high=0.5,name=\"dr_rate\")                    # 0.2\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers, \n",
    "              dim_num_dense_nodes,\n",
    "              dim_dr_rate\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cyclic Learning Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujMLNbxx1go1"
   },
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers,num_dense_nodes, dr_rate):\n",
    "    print(\"params\")\n",
    "    print(learning_rate, num_dense_layers, num_dense_nodes, dr_rate)\n",
    "    print()\n",
    "    clr = CyclicLR(base_lr=learning_rate, max_lr=learning_rate*6,\n",
    "                        step_size=1024., mode='exp_range',\n",
    "                        gamma=0.99994)\n",
    "\n",
    "    model = EmbeddingNet(cat_vars, cont_vars, embedding_sizes,\n",
    "                         learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         dr_rate = dr_rate\n",
    "                        )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    EPOCHS = 20\n",
    "    #named blackbox becuase it represents the structure\n",
    "    blackbox = model.fit(x=X_array,\n",
    "                        y=y,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=512,\n",
    "                        callbacks=[clr,],\n",
    "                        validation_data=(X_val_array, y_val),\n",
    "                        shuffle = True\n",
    "                        )\n",
    "    \n",
    "    val_mae = min(blackbox.history['val_loss'])\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # Print the classification accuracy.\n",
    "    print(\"val_loss: {0}\".format(val_mae))\n",
    "    print()\n",
    "    del model\n",
    "\n",
    "    K.clear_session()\n",
    "    tensorflow.reset_default_graph()\n",
    "    gc.collect()\n",
    "    return val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1566978197999,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "5YV57LU9LbgH",
    "outputId": "a58d7680-2505-4150-e283-00ff5f40dea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjcSKer6z6hJ"
   },
   "source": [
    "## 3. Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12404321,
     "status": "ok",
     "timestamp": 1566990666224,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "VovuWYlJ7Nm4",
    "outputId": "77351df3-1bba-4a16-a264-bb85af9c6602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params\n",
      "5e-05 3 512 0.2\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 1790079.2643 - val_loss: 790977.9941\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 802364.9909 - val_loss: 739542.5065\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 760595.5979 - val_loss: 729153.9583\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 742083.4323 - val_loss: 726254.8358\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 731187.7068 - val_loss: 724048.2447\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 723739.8087 - val_loss: 725567.3215\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 720053.2920 - val_loss: 725089.9728\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 716172.7126 - val_loss: 724144.9371\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 712923.7066 - val_loss: 724740.4672\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 36s 32us/step - loss: 710483.6535 - val_loss: 723987.1582\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 709020.9012 - val_loss: 723804.5413\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 706695.3718 - val_loss: 722595.9687\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 705776.8466 - val_loss: 722421.8561\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 704266.3069 - val_loss: 722205.6986\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 702951.4916 - val_loss: 720907.1314\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 701581.5083 - val_loss: 720144.4274\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 700994.8518 - val_loss: 718726.0569\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 700051.5167 - val_loss: 719158.7606\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 36s 32us/step - loss: 699406.0676 - val_loss: 718339.9982\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 36s 31us/step - loss: 697797.0793 - val_loss: 717395.9636\n",
      "--- 720.3539881706238 seconds ---\n",
      "val_loss: 717395.9636429546\n",
      "\n",
      "params\n",
      "5.485573804433523e-05 4 749 0.4037560406833253\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 43s 37us/step - loss: 1459275.1119 - val_loss: 746337.7788\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 867694.8513 - val_loss: 728164.4253\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 841540.5332 - val_loss: 724325.5558\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 829869.0434 - val_loss: 722355.8057\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 823916.2654 - val_loss: 723122.7441\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 819683.5685 - val_loss: 717675.5946\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 814349.5909 - val_loss: 721317.7119\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 809826.0634 - val_loss: 718845.9003\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 809204.5215 - val_loss: 716761.4859\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 806145.8963 - val_loss: 712040.8917\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 803825.2920 - val_loss: 713677.1929\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 801234.5967 - val_loss: 710712.4479\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 801924.8710 - val_loss: 711838.1934\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 800599.7366 - val_loss: 711264.9550\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 798498.2085 - val_loss: 707957.0199\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 797500.2937 - val_loss: 707626.4780\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 798172.3726 - val_loss: 707169.6672\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 795653.9857 - val_loss: 707035.0386\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 795262.2578 - val_loss: 706573.9581\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 42s 37us/step - loss: 794171.2128 - val_loss: 705453.5989\n",
      "--- 841.5302755832672 seconds ---\n",
      "val_loss: 705453.5989423405\n",
      "\n",
      "params\n",
      "1.2928483370449024e-05 3 692 0.19353584034904175\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 3071781.9439 - val_loss: 2004762.5520\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 1544384.3637 - val_loss: 1053267.8543\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 943913.4815 - val_loss: 836550.0889\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 861557.2213 - val_loss: 794739.3795\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 827982.7910 - val_loss: 771580.5615\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 806635.2573 - val_loss: 758184.8939\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 792494.4967 - val_loss: 748798.9013\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 781354.3147 - val_loss: 743745.1239\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 772721.2655 - val_loss: 738516.9421\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 766066.4255 - val_loss: 736037.3991\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 759985.7778 - val_loss: 733572.0729\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 754524.2477 - val_loss: 731841.6445\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 750563.7527 - val_loss: 730700.6080\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 747570.1132 - val_loss: 729748.6685\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 744073.3036 - val_loss: 728743.2712\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 742079.0916 - val_loss: 728105.7146\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 738535.6911 - val_loss: 727475.8621\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 737189.2188 - val_loss: 726937.9947\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 734361.3463 - val_loss: 726725.3195\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 732872.9364 - val_loss: 726618.9813\n",
      "--- 789.2449526786804 seconds ---\n",
      "val_loss: 726618.9813416923\n",
      "\n",
      "params\n",
      "0.0007679472564485746 4 823 0.4382393824414286\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 980026.7036 - val_loss: 718559.2005\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 824844.6510 - val_loss: 707885.1011\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 800194.1453 - val_loss: 670932.3917\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 765504.0563 - val_loss: 664820.5736\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 738162.8064 - val_loss: 625702.7210\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 716496.9415 - val_loss: 627243.0938\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 701658.5583 - val_loss: 583977.5421\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 686738.6983 - val_loss: 577119.6021\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 673599.7126 - val_loss: 553534.9916\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 664300.6056 - val_loss: 554325.8159\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 654329.7819 - val_loss: 534864.5388\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 647269.3938 - val_loss: 527061.2318\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 637805.8729 - val_loss: 543451.4962\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 633669.5921 - val_loss: 525820.8525\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 628108.0646 - val_loss: 517598.1163\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 620781.4765 - val_loss: 515493.1871\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 615023.1340 - val_loss: 523243.8717\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 610697.2175 - val_loss: 505001.7113\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 605602.0626 - val_loss: 502551.4296\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 601895.1733 - val_loss: 480870.2524\n",
      "--- 876.9595868587494 seconds ---\n",
      "val_loss: 480870.25243091094\n",
      "\n",
      "params\n",
      "0.0003391994740209797 2 913 0.30067234944849214\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 1247798.6033 - val_loss: 734755.6975\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 712711.0707 - val_loss: 732548.8335\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 698296.2141 - val_loss: 733896.6430\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 691026.9951 - val_loss: 725929.0475\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 685754.1836 - val_loss: 722697.7115\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 682002.4856 - val_loss: 720715.3145\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 679322.7166 - val_loss: 714198.1660\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 677702.8736 - val_loss: 710344.1693\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 676478.8776 - val_loss: 705937.6993\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 674845.8094 - val_loss: 705911.4103\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 673736.3239 - val_loss: 705353.1707\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 673402.1988 - val_loss: 704834.9399\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 672727.1930 - val_loss: 706457.5773\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 672018.6278 - val_loss: 706038.1360\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 671069.1383 - val_loss: 705125.5529\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 671168.3976 - val_loss: 707354.9200\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 670827.8567 - val_loss: 706789.1776\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 669616.3325 - val_loss: 707750.5222\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 669857.5292 - val_loss: 705866.9079\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 668847.4493 - val_loss: 705698.9416\n",
      "--- 802.3573067188263 seconds ---\n",
      "val_loss: 704834.9398882634\n",
      "\n",
      "params\n",
      "0.0009339877716646113 3 934 0.3588714838546196\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 45s 39us/step - loss: 901723.6656 - val_loss: 726681.3464\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 725163.4895 - val_loss: 697387.7627\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 702877.4170 - val_loss: 682996.2268\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 677636.3985 - val_loss: 665931.0291\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 651205.7768 - val_loss: 646931.1571\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 623526.5421 - val_loss: 619240.3061\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 598432.8041 - val_loss: 570486.2039\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 580219.9386 - val_loss: 555787.1550\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 564743.2401 - val_loss: 543148.9527\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 550690.9351 - val_loss: 534758.4062\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 537827.7267 - val_loss: 518514.6440\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 527513.0984 - val_loss: 505831.4830\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 519872.6292 - val_loss: 499285.4738\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 511677.1061 - val_loss: 497208.7950\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 504999.4215 - val_loss: 494796.6910\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 499492.7981 - val_loss: 490688.7648\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 494909.4940 - val_loss: 494287.6051\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 491341.8372 - val_loss: 481818.6539\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 486731.6576 - val_loss: 468886.6125\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 482887.1354 - val_loss: 474761.7518\n",
      "--- 875.8136472702026 seconds ---\n",
      "val_loss: 468886.61249360285\n",
      "\n",
      "params\n",
      "0.00010598769527456516 4 564 0.16023763096320542\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 1233901.7098 - val_loss: 726771.8506\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 38s 34us/step - loss: 742077.2267 - val_loss: 723465.5215\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 727109.8715 - val_loss: 722754.1563\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 719484.9683 - val_loss: 719413.4512\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 38s 34us/step - loss: 715672.2181 - val_loss: 715353.3373\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 38s 34us/step - loss: 713118.8837 - val_loss: 711372.2738\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 709424.8686 - val_loss: 707220.8758\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 38s 34us/step - loss: 706346.1672 - val_loss: 703608.7191\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 702033.7101 - val_loss: 697854.1157\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 38s 34us/step - loss: 696372.9272 - val_loss: 687534.9738\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 688941.6204 - val_loss: 683170.7265\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 683141.2309 - val_loss: 678395.0699\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 678582.7564 - val_loss: 678707.1814\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 673922.2263 - val_loss: 676907.7482\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 668744.6002 - val_loss: 675186.3080\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 665291.6529 - val_loss: 674482.9101\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 661739.4467 - val_loss: 671797.4915\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 660376.5041 - val_loss: 673827.9454\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 656981.4049 - val_loss: 672535.0270\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 655471.9933 - val_loss: 670485.6710\n",
      "--- 775.2840931415558 seconds ---\n",
      "val_loss: 670485.6709634084\n",
      "\n",
      "params\n",
      "5.781298905578968e-05 3 950 0.31916962194510373\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 1517071.2072 - val_loss: 755060.1632\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 779430.9948 - val_loss: 729815.4505\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 748966.5613 - val_loss: 726368.1696\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 734769.2963 - val_loss: 725888.9999\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 727239.3683 - val_loss: 724781.7102\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 721969.8947 - val_loss: 723548.2896\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 718431.2064 - val_loss: 721690.9010\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 716012.6631 - val_loss: 719985.6511\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 712772.2735 - val_loss: 719085.0475\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 711323.9374 - val_loss: 716717.5246\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 709808.3043 - val_loss: 716530.0275\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 708265.9144 - val_loss: 715404.2833\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 707091.7976 - val_loss: 714399.1257\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 705654.4004 - val_loss: 712509.1214\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 704212.5162 - val_loss: 712327.1126\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 704009.7216 - val_loss: 711429.3197\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 703876.5607 - val_loss: 710749.1325\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 702808.9025 - val_loss: 709396.2149\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 701447.1502 - val_loss: 709846.7810\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 701268.8197 - val_loss: 707724.2049\n",
      "--- 874.6627905368805 seconds ---\n",
      "val_loss: 707724.2049215285\n",
      "\n",
      "params\n",
      "0.0003261879003915737 2 947 0.1141412862943899\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 1234527.0950 - val_loss: 741189.0088\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 41s 35us/step - loss: 686428.3716 - val_loss: 736442.0269\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 671586.5699 - val_loss: 734937.0704\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 664321.4554 - val_loss: 729628.7258\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 658931.7286 - val_loss: 718708.9421\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 41s 35us/step - loss: 654985.2712 - val_loss: 713422.7873\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 41s 35us/step - loss: 652778.9805 - val_loss: 712084.5168\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 650717.1550 - val_loss: 710555.6197\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 649992.6463 - val_loss: 710999.5016\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 649197.4724 - val_loss: 711678.0295\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 41s 35us/step - loss: 648051.3569 - val_loss: 710787.3114\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 647460.3776 - val_loss: 709903.6406\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 646881.3625 - val_loss: 710620.8596\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 646463.4800 - val_loss: 710828.9802\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 645895.6671 - val_loss: 710625.6613\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 645577.4679 - val_loss: 710990.0044\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 644789.1689 - val_loss: 711747.3418\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 644606.1856 - val_loss: 709812.2723\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 643816.9673 - val_loss: 710904.4454\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 643358.8525 - val_loss: 708914.6991\n",
      "--- 812.4994609355927 seconds ---\n",
      "val_loss: 708914.699142784\n",
      "\n",
      "params\n",
      "0.0003048493448664363 3 720 0.1756787661321576\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 1039322.7815 - val_loss: 731682.0213\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 695515.1875 - val_loss: 723548.7797\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 685033.4079 - val_loss: 710794.9277\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 39s 35us/step - loss: 679503.7569 - val_loss: 712066.8833\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 675056.5868 - val_loss: 710688.1987\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 670058.6323 - val_loss: 702606.2114\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 660383.7146 - val_loss: 690986.2065\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 647912.0697 - val_loss: 678935.7680\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 640715.3588 - val_loss: 677745.5129\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 633545.8769 - val_loss: 670439.8634\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 627836.7795 - val_loss: 667897.8388\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 621299.1084 - val_loss: 665692.9851\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 615319.1533 - val_loss: 661147.7150\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 609006.9171 - val_loss: 657311.7100\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 39s 34us/step - loss: 602436.9043 - val_loss: 655092.7430\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 595633.8359 - val_loss: 652390.0976\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 589062.9720 - val_loss: 647612.7464\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 582039.4592 - val_loss: 644087.7352\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 40s 35us/step - loss: 576227.9591 - val_loss: 636866.1008\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 39s 35us/step - loss: 570245.8686 - val_loss: 635160.0060\n",
      "--- 794.6566295623779 seconds ---\n",
      "val_loss: 635160.0059919823\n",
      "\n",
      "params\n",
      "5.6874461040935414e-05 2 682 0.17531539427002796\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 2557589.8086 - val_loss: 1456961.0149\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 36s 32us/step - loss: 1049042.3896 - val_loss: 858726.0970\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 816117.2658 - val_loss: 781717.8169\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 769049.4644 - val_loss: 754496.3896\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 745292.2861 - val_loss: 743844.0706\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 730416.6060 - val_loss: 737600.6607\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 720355.0515 - val_loss: 734814.2984\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 712839.9190 - val_loss: 732946.0064\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 707426.1195 - val_loss: 732240.5612\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 703397.5641 - val_loss: 731320.7643\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 700032.0111 - val_loss: 731054.7865\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 697068.6993 - val_loss: 730963.6193\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 36s 32us/step - loss: 694846.7725 - val_loss: 730199.3398\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 693293.2047 - val_loss: 730593.5331\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 691485.9283 - val_loss: 730255.6040\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 690095.0700 - val_loss: 730013.0272\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 688575.6925 - val_loss: 729341.7438\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 687636.1463 - val_loss: 729636.2198\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 686338.9393 - val_loss: 729518.8773\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 37s 32us/step - loss: 685521.9778 - val_loss: 729518.7037\n",
      "--- 735.5850322246552 seconds ---\n",
      "val_loss: 729341.7438374275\n",
      "\n",
      "params\n",
      "0.0003760675571655575 4 643 0.4539489535515778\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 42s 36us/step - loss: 1083297.3192 - val_loss: 727578.9357\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 857974.0674 - val_loss: 734886.0264\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 845826.3604 - val_loss: 714135.7845\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 838150.6296 - val_loss: 717255.4939\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 831782.0836 - val_loss: 699471.6554\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 41s 35us/step - loss: 825391.4673 - val_loss: 693443.5578\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 41s 35us/step - loss: 816459.1515 - val_loss: 679943.1693\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 804544.6918 - val_loss: 669409.3438\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 796121.7610 - val_loss: 659124.7061\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 785110.7738 - val_loss: 652621.1550\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 777749.5163 - val_loss: 643234.7846\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 770646.6644 - val_loss: 641386.6365\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 765829.8899 - val_loss: 638162.7586\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 759682.3454 - val_loss: 631192.7132\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 748570.6975 - val_loss: 624824.0225\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 739511.6235 - val_loss: 615641.3108\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 734461.7892 - val_loss: 607051.5788\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 729134.8747 - val_loss: 601202.3209\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 728101.9248 - val_loss: 597931.1214\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 41s 36us/step - loss: 720872.5025 - val_loss: 585987.7011\n",
      "--- 818.700737953186 seconds ---\n",
      "val_loss: 585987.7010725861\n",
      "\n",
      "params\n",
      "0.0008767671522549524 4 948 0.41539302593403277\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 47s 41us/step - loss: 943474.3391 - val_loss: 717248.6634\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 792814.5160 - val_loss: 684399.0024\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 764441.4406 - val_loss: 666991.4874\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 735380.8893 - val_loss: 629514.9670\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 703687.9516 - val_loss: 632120.6062\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 680756.7686 - val_loss: 567276.4079\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 661866.4227 - val_loss: 571367.8348\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 647406.9769 - val_loss: 545022.4526\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 635479.0304 - val_loss: 538586.5018\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 622124.4867 - val_loss: 549974.7160\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 613530.3134 - val_loss: 517489.1898\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 604203.1913 - val_loss: 522426.0855\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 45s 40us/step - loss: 596697.6641 - val_loss: 513391.2179\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 590026.3195 - val_loss: 511928.1180\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 582406.8498 - val_loss: 507793.8432\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 576859.2923 - val_loss: 501055.8804\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 45s 40us/step - loss: 572110.7341 - val_loss: 500456.4658\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 567359.0632 - val_loss: 506200.9057\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 561759.1582 - val_loss: 508658.7583\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 46s 40us/step - loss: 558140.6881 - val_loss: 482306.8941\n",
      "--- 916.5805156230927 seconds ---\n",
      "val_loss: 482306.8941380928\n",
      "\n",
      "params\n",
      "0.0008877417379534484 3 899 0.4150413613881971\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 930067.7306 - val_loss: 712253.0186\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 745243.7471 - val_loss: 708333.4839\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 725824.8901 - val_loss: 687750.7525\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 707504.6325 - val_loss: 678408.5971\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 682806.6811 - val_loss: 657910.5648\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 662485.1560 - val_loss: 643489.5586\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 642081.7374 - val_loss: 602852.3468\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 625859.1151 - val_loss: 579034.6340\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 613283.7605 - val_loss: 566973.7362\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 602385.9348 - val_loss: 555778.7616\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 593337.3282 - val_loss: 547013.3574\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 583341.1233 - val_loss: 536074.3643\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 575529.1435 - val_loss: 538887.8192\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 569030.4091 - val_loss: 530239.2898\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 561225.4173 - val_loss: 515997.9733\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 557949.4973 - val_loss: 522808.6435\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 551454.4180 - val_loss: 520594.6974\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 548255.1932 - val_loss: 501931.6961\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 543383.4352 - val_loss: 502107.0043\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 43s 38us/step - loss: 538954.7432 - val_loss: 490476.0962\n",
      "--- 867.424991607666 seconds ---\n",
      "val_loss: 490476.09619157284\n",
      "\n",
      "params\n",
      "0.0008786309916108073 4 818 0.4262667911814309\n",
      "\n",
      "Train on 1144174 samples, validate on 23448 samples\n",
      "Epoch 1/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 976195.1353 - val_loss: 713634.2475\n",
      "Epoch 2/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 827768.4603 - val_loss: 697987.7314\n",
      "Epoch 3/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 797887.2739 - val_loss: 673316.3206\n",
      "Epoch 4/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 775920.2635 - val_loss: 655721.3884\n",
      "Epoch 5/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 756325.7022 - val_loss: 624870.1728\n",
      "Epoch 6/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 735947.9398 - val_loss: 602228.4929\n",
      "Epoch 7/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 720125.1934 - val_loss: 570735.8258\n",
      "Epoch 8/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 703330.0038 - val_loss: 561245.6006\n",
      "Epoch 9/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 687305.5632 - val_loss: 553538.7675\n",
      "Epoch 10/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 676294.1998 - val_loss: 526787.4983\n",
      "Epoch 11/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 666805.8231 - val_loss: 534902.6016\n",
      "Epoch 12/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 657964.1065 - val_loss: 525467.9432\n",
      "Epoch 13/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 645166.5074 - val_loss: 519324.0717\n",
      "Epoch 14/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 634837.3493 - val_loss: 549517.0602\n",
      "Epoch 15/20\n",
      "1144174/1144174 [==============================] - 44s 39us/step - loss: 628338.0512 - val_loss: 499623.0542\n",
      "Epoch 16/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 619742.9178 - val_loss: 515245.8613\n",
      "Epoch 17/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 615211.2131 - val_loss: 512856.2657\n",
      "Epoch 18/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 610673.1534 - val_loss: 532245.8650\n",
      "Epoch 19/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 607234.9386 - val_loss: 490173.5610\n",
      "Epoch 20/20\n",
      "1144174/1144174 [==============================] - 44s 38us/step - loss: 601268.2034 - val_loss: 498168.5907\n",
      "--- 877.9528558254242 seconds ---\n",
      "val_loss: 490173.5609860116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()\n",
    "default_parameters = [0.00005, 3, 512, 0.2]\n",
    "res_gp = gp_minimize(func=fitness,\n",
    "                     dimensions=dimensions,\n",
    "                     n_calls = 15,\n",
    "                     n_jobs=-1,\n",
    "                     kappa = 5,\n",
    "                     x0=default_parameters)\n",
    "\n",
    "report = pd.concat([pd.DataFrame(\n",
    "                  res_gp.x_iters, \n",
    "                  columns = [\"learning_rate\", \"num_dense_layers\",\"num_dense_nodes\",\"dr_rate\"]),\n",
    "                  (pd.Series(res_gp.func_vals, name=\"mae\"))], axis=1)\n",
    "\n",
    "report.to_csv('./submit_0825/report_nn_skopt_0828_no0.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1566990752150,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "03075001147961339929"
     },
     "user_tz": -540
    },
    "id": "HudQrsxAGbME",
    "outputId": "8f19ef8d-1de1-4367-b0b1-d3c1546ea6b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_dense_layers</th>\n",
       "      <th>num_dense_nodes</th>\n",
       "      <th>dr_rate</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>3</td>\n",
       "      <td>934</td>\n",
       "      <td>0.358871</td>\n",
       "      <td>468886.612494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000768</td>\n",
       "      <td>4</td>\n",
       "      <td>823</td>\n",
       "      <td>0.438239</td>\n",
       "      <td>480870.252431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000877</td>\n",
       "      <td>4</td>\n",
       "      <td>948</td>\n",
       "      <td>0.415393</td>\n",
       "      <td>482306.894138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000879</td>\n",
       "      <td>4</td>\n",
       "      <td>818</td>\n",
       "      <td>0.426267</td>\n",
       "      <td>490173.560986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000888</td>\n",
       "      <td>3</td>\n",
       "      <td>899</td>\n",
       "      <td>0.415041</td>\n",
       "      <td>490476.096192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000376</td>\n",
       "      <td>4</td>\n",
       "      <td>643</td>\n",
       "      <td>0.453949</td>\n",
       "      <td>585987.701073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>3</td>\n",
       "      <td>720</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>635160.005992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000106</td>\n",
       "      <td>4</td>\n",
       "      <td>564</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>670485.670963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000339</td>\n",
       "      <td>2</td>\n",
       "      <td>913</td>\n",
       "      <td>0.300672</td>\n",
       "      <td>704834.939888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>4</td>\n",
       "      <td>749</td>\n",
       "      <td>0.403756</td>\n",
       "      <td>705453.598942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "      <td>950</td>\n",
       "      <td>0.319170</td>\n",
       "      <td>707724.204922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000326</td>\n",
       "      <td>2</td>\n",
       "      <td>947</td>\n",
       "      <td>0.114141</td>\n",
       "      <td>708914.699143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000050</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>717395.963643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>3</td>\n",
       "      <td>692</td>\n",
       "      <td>0.193536</td>\n",
       "      <td>726618.981342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>2</td>\n",
       "      <td>682</td>\n",
       "      <td>0.175315</td>\n",
       "      <td>729341.743837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  num_dense_layers  num_dense_nodes   dr_rate            mae\n",
       "5        0.000934                 3              934  0.358871  468886.612494\n",
       "3        0.000768                 4              823  0.438239  480870.252431\n",
       "12       0.000877                 4              948  0.415393  482306.894138\n",
       "14       0.000879                 4              818  0.426267  490173.560986\n",
       "13       0.000888                 3              899  0.415041  490476.096192\n",
       "11       0.000376                 4              643  0.453949  585987.701073\n",
       "9        0.000305                 3              720  0.175679  635160.005992\n",
       "6        0.000106                 4              564  0.160238  670485.670963\n",
       "4        0.000339                 2              913  0.300672  704834.939888\n",
       "1        0.000055                 4              749  0.403756  705453.598942\n",
       "7        0.000058                 3              950  0.319170  707724.204922\n",
       "8        0.000326                 2              947  0.114141  708914.699143\n",
       "0        0.000050                 3              512  0.200000  717395.963643\n",
       "2        0.000013                 3              692  0.193536  726618.981342\n",
       "10       0.000057                 2              682  0.175315  729341.743837"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.sort_values('mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1C8HPM60V3N"
   },
   "source": [
    "## 4. Train & Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXEm3jmf0X_Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, BatchNormalization, Concatenate\n",
    "from keras.layers import Dropout, Dense, Input, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.regularizers import l2, l1\n",
    "import tensorflow\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zf4UkhFr0tsz"
   },
   "outputs": [],
   "source": [
    "from CLR.clr_callback import CyclicLR\n",
    "import tensorflow\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32kOOnbY0vBn"
   },
   "outputs": [],
   "source": [
    "def EmbeddingNet(cat_vars, cont_vars, embedding_sizes, learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, dr_rate):\n",
    "    inputs = []\n",
    "    embed_layers = []\n",
    "    for (c, (in_size, out_size)) in zip(cat_vars, embedding_sizes):\n",
    "        i = Input(shape=(1,))\n",
    "        o = Embedding(in_size, out_size, name=c)(i)\n",
    "        o = Reshape(target_shape=(out_size,))(o)\n",
    "        inputs.append(i)\n",
    "        embed_layers.append(o)\n",
    "\n",
    "\n",
    "    embed = Concatenate()(embed_layers)\n",
    "    embed = Dropout(dr_rate)(embed)\n",
    "\n",
    "    cont_input = Input(shape=(len(cont_vars),))\n",
    "    inputs.append(cont_input)\n",
    "\n",
    "    x = Concatenate()([embed, cont_input])\n",
    "\n",
    "    for i in range(num_dense_layers):\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "        x = Dense(int(num_dense_nodes / (2**(i))) ,\n",
    "                  kernel_initializer='he_normal')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(dr_rate)(x)\n",
    "\n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('linear')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBnC0b3b0wVv"
   },
   "outputs": [],
   "source": [
    "LR = 0.0003 \n",
    "NDL = 2\n",
    "NDN =  800\n",
    "DR = 0.35\n",
    "\n",
    "model_weight_loc = './BM_weights_0828_check.hdf5'\n",
    "\n",
    "\n",
    "model = EmbeddingNet(cat_vars, cont_vars, embedding_sizes,\n",
    "                     learning_rate=LR,\n",
    "                     num_dense_layers=NDL,\n",
    "                     num_dense_nodes=NDN,\n",
    "                     dr_rate = DR\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qerIkYa0xnv"
   },
   "outputs": [],
   "source": [
    "from CLR.clr_callback import CyclicLR\n",
    "\n",
    "clr = CyclicLR(base_lr=LR, max_lr=LR*6,\n",
    "                    step_size=1024., mode='exp_range',\n",
    "                    gamma=0.99994)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_weight_loc, monitor='val_loss',\n",
    "                             save_best_only=True)\n",
    "\n",
    "EPOCHS = 40\n",
    "#named blackbox becuase it represents the structure\n",
    "blackbox = model.fit(x=X_array,\n",
    "                    y=y,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=512,\n",
    "                    callbacks=[clr, checkpoint],\n",
    "                    validation_data=(X_val_array, y_val),\n",
    "                    shuffle = True\n",
    "                    )\n",
    "\n",
    "val_mae = min(blackbox.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6CBVNSp044f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import load_model\n",
    "\n",
    "saved_model = EmbeddingNet(cat_vars, cont_vars, embedding_sizes,\n",
    "                     learning_rate=LR,\n",
    "                     num_dense_layers=NDL,\n",
    "                     num_dense_nodes=NDN,\n",
    "                     dr_rate = DR\n",
    "                    )\n",
    "\n",
    "saved_model.load_weights(model_weight_loc)\n",
    "\n",
    "pred =  saved_model.predict(x = X_test_array)\n",
    "\n",
    "store_id_inversed = encoders['store_id'].inverse_transform(X_test.store_id.values)\n",
    "\n",
    "predicted = pd.DataFrame(\n",
    "    {'store_id': store_id_inversed,\n",
    "     'pred': pred.reshape(len(pred))\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- References:\n",
    "    - Entity Embedding\n",
    "        - https://arxiv.org/pdf/1604.06737.pdf\n",
    "        - https://www.johnwittenauer.net/deep-learning-with-keras-structured-time-series/\n",
    "        - https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb\n",
    "    \n",
    "    - Cyclic Learning Rate\n",
    "        - https://arxiv.org/abs/1506.01186\n",
    "        - https://github.com/bckenstler/CLR\n",
    "\n",
    "    - Bayesian Optimization\n",
    "        - https://scikit-optimize.github.io/#skopt.gp_minimize\n",
    "        - https://medium.com/@crawftv/parameter-hyperparameter-tuning-with-bayesian-optimization-7acf42d348e1\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "skopt_EntityEmbedding_Trials.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
