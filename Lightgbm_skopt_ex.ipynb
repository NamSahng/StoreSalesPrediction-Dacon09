{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23373,
     "status": "ok",
     "timestamp": 1566275401974,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "XG4lVCI22fGB",
    "outputId": "bbc52e9c-ae0f-4de7-de3b-45baee95f330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "RANDOM_STATE = 2019\n",
    "np.random.seed(RANDOM_STATE) \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "def inverse_boxcox(y, lambda_):\n",
    "    return np.exp(y) if lambda_ == 0 else np.exp(np.log(lambda_ * y + 1) / lambda_)\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "os.chdir(\"/gdrive/My Drive/Colab Notebooks/dacon\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zkM_IC9I39vK"
   },
   "outputs": [],
   "source": [
    "resampled_existing = pd.read_csv('data/comp_9th/resampled_existing_0819.csv',parse_dates=['date'])\n",
    "resampled_w0 = pd.read_csv('data/comp_9th/resampled_w0_0819.csv',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFH6bLoA57aY"
   },
   "outputs": [],
   "source": [
    "def rename(df):\n",
    "    df.rename(columns={ 'cycle_idx_week1_x': 'cycle_idx_week1' ,\n",
    "                      'cycle_idx_week2_x': 'cycle_idx_week2',\n",
    "                      'cycle_idx_week4_x': 'cycle_idx_week4'},\n",
    "            inplace=True)\n",
    "    df.rename(columns={ 'cycle_idx_week1_y': 'max_cidx_week1' ,\n",
    "                    'cycle_idx_week2_y': 'max_cidx_week2',\n",
    "                    'cycle_idx_week4_y': 'max_cidx_week4'},\n",
    "          inplace=True)\n",
    "    return df\n",
    "\n",
    "resampled_w0 = rename(resampled_w0)\n",
    "resampled_existing = rename(resampled_existing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWFl2qmM5X8v"
   },
   "outputs": [],
   "source": [
    "def check(colname):\n",
    "    if ('h-day_cnt_' in colname) or ('pt_cnt_'  in colname) or ('inst_cnt_' in colname):\n",
    "        if '13' in colname:\n",
    "            return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "remained_col = [i for i in resampled_w0.columns.values if check(i)]\n",
    "temp_col = [i for i in resampled_w0.columns.values if not check(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3208,
     "status": "ok",
     "timestamp": 1566275436077,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "sZWqgbaT_soT",
    "outputId": "bdfdad6b-bca7-4f1d-8ff0-991d2644aba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resampled_existing_full = resampled_existing.copy()\n",
    "resampled_existing_121 = resampled_existing[remained_col].copy()\n",
    "resampled_w0_full = resampled_w0.copy()\n",
    "resampled_w0_121 = resampled_w0[remained_col].copy()\n",
    "\n",
    "del resampled_existing, resampled_w0\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6300,
     "status": "ok",
     "timestamp": 1566275483985,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "cG5IVCdmvduB",
    "outputId": "a82beac5-c55d-4da0-d0a4-2a9f73f1a742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/44/60f82c97d1caa98752c7da2c1681cab5c7a390a0fdd3a55fac672b321cac/scikit_optimize-0.5.2-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 9.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.16.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->scikit-optimize) (0.13.2)\n",
      "Installing collected packages: scikit-optimize\n",
      "Successfully installed scikit-optimize-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5285,
     "status": "ok",
     "timestamp": 1566275484479,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "lFIL1-TPC1wv",
    "outputId": "92e6e32d-7725-4ac7-9f7a-de475ec019de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:\n",
      "\n",
      "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install scikit-optimize\n",
    "#import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JO2J8pIDy4I"
   },
   "outputs": [],
   "source": [
    "def objective(values):\n",
    "    params = {\n",
    "              'max_depth': values[0],  # 0\n",
    "              'task': 'train',\n",
    "              'num_leaves': int((2**(values[0]) ) -1) , \n",
    "              'learning_rate': values[1],    # 1\n",
    "              'feature_fraction': values[2], # 2\n",
    "              'lambda_l1': values[3],       # 3\n",
    "              'lambda_l2': values[4],         # 4\n",
    "              'bagging_fraction': values[5], # 5\n",
    "              'bagging_freq': values[6],       #  6\n",
    "              'max_bin': values[7],           # 7\n",
    "              'metric':'mae',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'objective': 'regression_l1',\n",
    "              'verbose': -1,\n",
    "              'seed': RANDOM_STATE\n",
    "              }\n",
    "\n",
    "    print('\\nNext set of params.....',params)\n",
    "    print(\"with data:   \"+values[8])\n",
    "    if values[8] == 'full':\n",
    "        resampled = resampled_w0_full.copy()\n",
    "    elif values[8] =='121':\n",
    "        resampled = resampled_w0_121.copy()\n",
    "\n",
    "    real_train = resampled[resampled['date'] <= pd.to_datetime('2018-11-28') ]\n",
    "    real_test = resampled[(resampled['Year'] == 2018) &\n",
    "                          (resampled['Month'] == 11) &\n",
    "                          (resampled['Day'] == 29) ]\n",
    "\n",
    "    ##    \n",
    "    original_target = real_train.y.values\n",
    "    target, lambda_prophet = stats.boxcox(real_train['y'] + 1)\n",
    "    len_train=target.shape[0]\n",
    "    merged_df = pd.concat([real_train, real_test])\n",
    "    merged_df.drop(['y','date'],axis=1,inplace=True)\n",
    "\n",
    "    cate = ['store_id',  'Month', 'Week', 'Day', 'Dayofweek','Dayofyear', \n",
    "            'weekofyear','type_bus', 'high_region', 'full_region','cur_zero',\n",
    "            'cycle_idx_week1', 'cycle_idx_week2', 'cycle_idx_week4']\n",
    "\n",
    "    columns = merged_df.columns.values\n",
    "    col_dict = {}\n",
    "    for i,colname in enumerate(columns):\n",
    "      col_dict[colname] = i\n",
    "    cate_feat2num = [col_dict[colname] for colname in cate]\n",
    "\n",
    "    # do the training\n",
    "    num_folds = 3\n",
    "    test_x = merged_df[len_train:].values\n",
    "    all_x = merged_df[:len_train].values\n",
    "    all_y = target # removing what we did earlier\n",
    "    oof_preds = np.zeros([all_y.shape[0]])\n",
    "    sub_preds = np.zeros([test_x.shape[0]])\n",
    "    folds = KFold(n_splits=num_folds, shuffle=True, random_state=2019)\n",
    "    ##\n",
    "    num_boost_round = 3000\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(all_x)):\n",
    "        start_time = time.time()\n",
    "        train_x, train_y = all_x[train_idx], all_y[train_idx]\n",
    "        valid_x, valid_y = all_x[valid_idx], all_y[valid_idx]\n",
    "        lgb_train = lgb.Dataset(train_x,train_y)\n",
    "        lgb_valid = lgb.Dataset(valid_x,valid_y)\n",
    "\n",
    "        # train\n",
    "\n",
    "        gbm = lgb.train(params, lgb_train, num_boost_round= num_boost_round, \n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            early_stopping_rounds=100, verbose_eval=1500)\n",
    "        \n",
    "        oof_preds[valid_idx] = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "        sub_preds[:] += gbm.predict(test_x, num_iteration=gbm.best_iteration) / folds.n_splits\n",
    "        valid_idx += 1\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    sub_preds = inverse_boxcox(sub_preds , lambda_prophet) - 1\n",
    "    oof_preds = inverse_boxcox(oof_preds , lambda_prophet) - 1\n",
    "    y_true = real_test['y'].values\n",
    "\n",
    "    sub_preds = np.nan_to_num(sub_preds)\n",
    "    mae_1129 = mean_absolute_error(y_true = y_true, y_pred= sub_preds )\n",
    "    \n",
    "\n",
    "    print(len(y_true))\n",
    "    print(\"mae on 11/29  :\"+ str(mae_1129) )\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return mae_1129\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pj9aOO_JuKdk"
   },
   "outputs": [],
   "source": [
    "space  = [Integer(8, 12, name='max_depth'), # 0\n",
    "          Real(0.05, 0.25,  name='learning_rate',prior='log-uniform',), # 1\n",
    "          Real(0.7, 0.9, name='feature_fraction'), # 2\n",
    "          Real(0.01, 0.2,  name='lambda_l1'), # 3\n",
    "          Real(0.01, 0.2,  name='lambda_l2'), # 4\n",
    "          Real(0.3, 0.9,  name='bagging_fraction'), # 5\n",
    "          Integer(5, 100, name='bagging_freq'), # 6\n",
    "          Integer(50, 255, name='max_bin'), #7\n",
    "          Categorical(['full','121'], name='data') # 8\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MdyjnxO3AFx"
   },
   "source": [
    "- https://scikit-optimize.github.io/#skopt.gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10904561,
     "status": "ok",
     "timestamp": 1566286744100,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "POSgJJG4TSDE",
    "outputId": "d3c086ec-c86a-465b-c5e2-4929b1589d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'lambda_l1': 0.06, 'lambda_l2': 0.1, 'bagging_fraction': 0.8, 'bagging_freq': 30, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.36669\tvalid_1's l1: 14.7675\n",
      "[3000]\ttraining's l1: 8.11785\tvalid_1's l1: 14.2498\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.11785\tvalid_1's l1: 14.2498\n",
      "--- 220.92199087142944 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.39211\tvalid_1's l1: 14.6876\n",
      "[3000]\ttraining's l1: 8.17768\tvalid_1's l1: 14.168\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.17768\tvalid_1's l1: 14.168\n",
      "--- 216.64696526527405 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.26952\tvalid_1's l1: 14.5439\n",
      "[3000]\ttraining's l1: 8.00256\tvalid_1's l1: 13.9972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.00256\tvalid_1's l1: 13.9972\n",
      "--- 223.66632628440857 seconds ---\n",
      "1967\n",
      "mae on 11/29  :557695.5809243312\n",
      "\n",
      "Next set of params..... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.11614746341176702, 'feature_fraction': 0.8091264808742366, 'lambda_l1': 0.10647214537333566, 'lambda_l2': 0.1083314750853381, 'bagging_fraction': 0.7346420453587098, 'bagging_freq': 46, 'max_bin': 232, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.7118\tvalid_1's l1: 15.8951\n",
      "[3000]\ttraining's l1: 10.4937\tvalid_1's l1: 15.3617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.4937\tvalid_1's l1: 15.3617\n",
      "--- 164.26452469825745 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.9956\tvalid_1's l1: 15.9425\n",
      "[3000]\ttraining's l1: 10.6316\tvalid_1's l1: 15.3177\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.6316\tvalid_1's l1: 15.3177\n",
      "--- 161.99536991119385 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.9072\tvalid_1's l1: 15.7874\n",
      "[3000]\ttraining's l1: 10.612\tvalid_1's l1: 15.2144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.612\tvalid_1's l1: 15.2144\n",
      "--- 162.03687286376953 seconds ---\n",
      "1967\n",
      "mae on 11/29  :600922.5403231935\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.10375278015379787, 'feature_fraction': 0.7098239111346972, 'lambda_l1': 0.17370340890400707, 'lambda_l2': 0.03314958183624209, 'bagging_fraction': 0.7149684145363726, 'bagging_freq': 88, 'max_bin': 122, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.4296\tvalid_1's l1: 16.1881\n",
      "[3000]\ttraining's l1: 11.3249\tvalid_1's l1: 15.7157\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 11.3249\tvalid_1's l1: 15.7157\n",
      "--- 146.95588159561157 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.4683\tvalid_1's l1: 16.1567\n",
      "[3000]\ttraining's l1: 11.2283\tvalid_1's l1: 15.6146\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 11.2283\tvalid_1's l1: 15.6146\n",
      "--- 148.65579462051392 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.6802\tvalid_1's l1: 16.2589\n",
      "[3000]\ttraining's l1: 11.4298\tvalid_1's l1: 15.7181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 11.4298\tvalid_1's l1: 15.7181\n",
      "--- 149.07768845558167 seconds ---\n",
      "1967\n",
      "mae on 11/29  :601256.5592810918\n",
      "\n",
      "Next set of params..... {'max_depth': 11, 'task': 'train', 'num_leaves': 2047, 'learning_rate': 0.10859301111949785, 'feature_fraction': 0.8212123611246073, 'lambda_l1': 0.019668761840937302, 'lambda_l2': 0.14658569312890998, 'bagging_fraction': 0.6056686991154395, 'bagging_freq': 68, 'max_bin': 132, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.40482\tvalid_1's l1: 15.2604\n",
      "[3000]\ttraining's l1: 8.08364\tvalid_1's l1: 14.7654\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.08364\tvalid_1's l1: 14.7654\n",
      "--- 248.92937850952148 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.50313\tvalid_1's l1: 15.2557\n",
      "[3000]\ttraining's l1: 8.233\tvalid_1's l1: 14.7767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.233\tvalid_1's l1: 14.7767\n",
      "--- 240.86879134178162 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.35543\tvalid_1's l1: 15.1041\n",
      "[3000]\ttraining's l1: 8.22172\tvalid_1's l1: 14.6797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.22172\tvalid_1's l1: 14.6797\n",
      "--- 239.445086479187 seconds ---\n",
      "1967\n",
      "mae on 11/29  :574533.4980899144\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.06048543582002651, 'feature_fraction': 0.7030021517045607, 'lambda_l1': 0.15911899312781935, 'lambda_l2': 0.09765537301931193, 'bagging_fraction': 0.3367098250074593, 'bagging_freq': 59, 'max_bin': 197, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.9881\tvalid_1's l1: 16.2842\n",
      "[3000]\ttraining's l1: 10.269\tvalid_1's l1: 15.6224\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.269\tvalid_1's l1: 15.6224\n",
      "--- 170.5271143913269 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.0673\tvalid_1's l1: 16.234\n",
      "[3000]\ttraining's l1: 10.4054\tvalid_1's l1: 15.6065\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.4054\tvalid_1's l1: 15.6065\n",
      "--- 170.47319388389587 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.1315\tvalid_1's l1: 16.1109\n",
      "[3000]\ttraining's l1: 10.3821\tvalid_1's l1: 15.4303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.3821\tvalid_1's l1: 15.4303\n",
      "--- 169.06337904930115 seconds ---\n",
      "1967\n",
      "mae on 11/29  :612468.2923788037\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.0655128916989167, 'feature_fraction': 0.8471088324337869, 'lambda_l1': 0.17784017531463467, 'lambda_l2': 0.12353797501366898, 'bagging_fraction': 0.6087191577575439, 'bagging_freq': 61, 'max_bin': 91, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.7513\tvalid_1's l1: 15.8839\n",
      "[3000]\ttraining's l1: 10.2474\tvalid_1's l1: 15.2328\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.2474\tvalid_1's l1: 15.2328\n",
      "--- 169.18107557296753 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.681\tvalid_1's l1: 15.7333\n",
      "[3000]\ttraining's l1: 10.3029\tvalid_1's l1: 15.1592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.3029\tvalid_1's l1: 15.1592\n",
      "--- 166.41493320465088 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.7013\tvalid_1's l1: 15.6508\n",
      "[3000]\ttraining's l1: 10.3061\tvalid_1's l1: 15.0727\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.3061\tvalid_1's l1: 15.0727\n",
      "--- 167.3624496459961 seconds ---\n",
      "1967\n",
      "mae on 11/29  :589026.256646381\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.17410917265597495, 'feature_fraction': 0.7053025448039538, 'lambda_l1': 0.1291039037994003, 'lambda_l2': 0.03621953677058266, 'bagging_fraction': 0.47732892166011875, 'bagging_freq': 96, 'max_bin': 151, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.52771\tvalid_1's l1: 15.5819\n",
      "[3000]\ttraining's l1: 8.0287\tvalid_1's l1: 15.1073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.0287\tvalid_1's l1: 15.1073\n",
      "--- 164.88114500045776 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.86152\tvalid_1's l1: 15.6116\n",
      "[3000]\ttraining's l1: 8.21031\tvalid_1's l1: 15.0669\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.21031\tvalid_1's l1: 15.0669\n",
      "--- 159.7245156764984 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.65382\tvalid_1's l1: 15.3844\n",
      "[3000]\ttraining's l1: 8.15438\tvalid_1's l1: 14.9319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.15438\tvalid_1's l1: 14.9319\n",
      "--- 160.28970336914062 seconds ---\n",
      "1967\n",
      "mae on 11/29  :582939.7359795755\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.07803489145727022, 'feature_fraction': 0.8273867499483304, 'lambda_l1': 0.08496231118651096, 'lambda_l2': 0.15995271791649995, 'bagging_fraction': 0.72431869560092, 'bagging_freq': 44, 'max_bin': 122, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.906\tvalid_1's l1: 16.4327\n",
      "[3000]\ttraining's l1: 11.7303\tvalid_1's l1: 15.906\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 11.7303\tvalid_1's l1: 15.906\n",
      "--- 168.777898311615 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.8099\tvalid_1's l1: 16.3576\n",
      "[3000]\ttraining's l1: 11.5165\tvalid_1's l1: 15.7548\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 11.5165\tvalid_1's l1: 15.7548\n",
      "--- 171.56239414215088 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.8645\tvalid_1's l1: 16.1151\n",
      "[3000]\ttraining's l1: 11.4962\tvalid_1's l1: 15.4673\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 11.4962\tvalid_1's l1: 15.4673\n",
      "--- 169.8901171684265 seconds ---\n",
      "1967\n",
      "mae on 11/29  :602596.283010329\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.22366668275112497, 'feature_fraction': 0.7969092381772256, 'lambda_l1': 0.1632238480818866, 'lambda_l2': 0.0658230234124877, 'bagging_fraction': 0.8789297808569481, 'bagging_freq': 39, 'max_bin': 225, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.4578\tvalid_1's l1: 16.0384\n",
      "[3000]\ttraining's l1: 10.6168\tvalid_1's l1: 15.7146\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.6168\tvalid_1's l1: 15.7146\n",
      "--- 163.14239740371704 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.432\tvalid_1's l1: 15.9631\n",
      "[3000]\ttraining's l1: 10.5639\tvalid_1's l1: 15.5977\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.5639\tvalid_1's l1: 15.5977\n",
      "--- 164.2556562423706 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.0377\tvalid_1's l1: 15.5232\n",
      "[3000]\ttraining's l1: 10.1485\tvalid_1's l1: 15.1883\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.1485\tvalid_1's l1: 15.1883\n",
      "--- 167.41197085380554 seconds ---\n",
      "1967\n",
      "mae on 11/29  :607588.1122265968\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.06125233786542991, 'feature_fraction': 0.7962601330218323, 'lambda_l1': 0.12601360113650834, 'lambda_l2': 0.1758294253664974, 'bagging_fraction': 0.4712820517500648, 'bagging_freq': 28, 'max_bin': 148, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.1541\tvalid_1's l1: 16.0654\n",
      "[3000]\ttraining's l1: 10.5289\tvalid_1's l1: 15.3973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.5289\tvalid_1's l1: 15.3973\n",
      "--- 163.16094064712524 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.1495\tvalid_1's l1: 15.991\n",
      "[3000]\ttraining's l1: 10.5779\tvalid_1's l1: 15.3403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.5779\tvalid_1's l1: 15.3403\n",
      "--- 164.16182565689087 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 12.0393\tvalid_1's l1: 15.8823\n",
      "[3000]\ttraining's l1: 10.5033\tvalid_1's l1: 15.2528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.5033\tvalid_1's l1: 15.2528\n",
      "--- 166.35156869888306 seconds ---\n",
      "1967\n",
      "mae on 11/29  :597177.7262280817\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.1984183089078719, 'feature_fraction': 0.7322894075268152, 'lambda_l1': 0.09154805216931897, 'lambda_l2': 0.042391222524376944, 'bagging_fraction': 0.5617605879645696, 'bagging_freq': 52, 'max_bin': 131, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 10.388\tvalid_1's l1: 15.8835\n",
      "[3000]\ttraining's l1: 9.1469\tvalid_1's l1: 15.4815\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 9.1469\tvalid_1's l1: 15.4815\n",
      "--- 153.47437167167664 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 10.409\tvalid_1's l1: 15.8126\n",
      "[3000]\ttraining's l1: 9.09912\tvalid_1's l1: 15.381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 9.09912\tvalid_1's l1: 15.381\n",
      "--- 153.59052515029907 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 10.262\tvalid_1's l1: 15.6646\n",
      "[3000]\ttraining's l1: 8.87981\tvalid_1's l1: 15.2095\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.87981\tvalid_1's l1: 15.2095\n",
      "--- 155.20901012420654 seconds ---\n",
      "1967\n",
      "mae on 11/29  :593625.9882398893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.0903663190156297, 'feature_fraction': 0.7979273938699976, 'lambda_l1': 0.055875203741607225, 'lambda_l2': 0.04498642503377282, 'bagging_fraction': 0.81456566956677, 'bagging_freq': 99, 'max_bin': 135, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 10.2326\tvalid_1's l1: 15.2476\n",
      "[3000]\ttraining's l1: 9.16047\tvalid_1's l1: 14.7855\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 9.16047\tvalid_1's l1: 14.7855\n",
      "--- 231.7726604938507 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 10.3912\tvalid_1's l1: 15.3259\n",
      "[3000]\ttraining's l1: 9.31304\tvalid_1's l1: 14.8718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 9.31304\tvalid_1's l1: 14.8718\n",
      "--- 229.17601776123047 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 10.356\tvalid_1's l1: 15.12\n",
      "[3000]\ttraining's l1: 9.38154\tvalid_1's l1: 14.7029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 9.38154\tvalid_1's l1: 14.7029\n",
      "--- 225.14297914505005 seconds ---\n",
      "1967\n",
      "mae on 11/29  :591418.6804824256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.15608334809478594, 'feature_fraction': 0.7078648981299098, 'lambda_l1': 0.1154271450784759, 'lambda_l2': 0.15416081271788987, 'bagging_fraction': 0.5238126687597022, 'bagging_freq': 78, 'max_bin': 149, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.61442\tvalid_1's l1: 15.5438\n",
      "[3000]\ttraining's l1: 8.13548\tvalid_1's l1: 15.0174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.13548\tvalid_1's l1: 15.0174\n",
      "--- 167.9083833694458 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.58204\tvalid_1's l1: 15.4116\n",
      "[3000]\ttraining's l1: 8.10374\tvalid_1's l1: 14.9128\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.10374\tvalid_1's l1: 14.9128\n",
      "--- 168.64978408813477 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.62738\tvalid_1's l1: 15.2632\n",
      "[3000]\ttraining's l1: 8.11557\tvalid_1's l1: 14.7547\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.11557\tvalid_1's l1: 14.7547\n",
      "--- 170.2502679824829 seconds ---\n",
      "1967\n",
      "mae on 11/29  :574554.5877174295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.06551218792543619, 'feature_fraction': 0.8704089018639194, 'lambda_l1': 0.17784194667353975, 'lambda_l2': 0.033017291353052786, 'bagging_fraction': 0.6087306158162247, 'bagging_freq': 81, 'max_bin': 91, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.7672\tvalid_1's l1: 15.8154\n",
      "[3000]\ttraining's l1: 10.2124\tvalid_1's l1: 15.1332\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.2124\tvalid_1's l1: 15.1332\n",
      "--- 171.04439902305603 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.8951\tvalid_1's l1: 15.8719\n",
      "[3000]\ttraining's l1: 10.3229\tvalid_1's l1: 15.1953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.3229\tvalid_1's l1: 15.1953\n",
      "--- 167.82598996162415 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 11.7045\tvalid_1's l1: 15.5681\n",
      "[3000]\ttraining's l1: 10.2609\tvalid_1's l1: 14.9358\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 10.2609\tvalid_1's l1: 14.9358\n",
      "--- 168.53197741508484 seconds ---\n",
      "1967\n",
      "mae on 11/29  :580320.2649551759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.10000000000631874, 'feature_fraction': 0.7172399306039093, 'lambda_l1': 0.05999999995014267, 'lambda_l2': 0.15809378525827775, 'bagging_fraction': 0.8000000001623488, 'bagging_freq': 65, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.58407\tvalid_1's l1: 14.8971\n",
      "[3000]\ttraining's l1: 8.31091\tvalid_1's l1: 14.363\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.31091\tvalid_1's l1: 14.363\n",
      "--- 202.1344473361969 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.50331\tvalid_1's l1: 14.7888\n",
      "[3000]\ttraining's l1: 8.23883\tvalid_1's l1: 14.2365\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.23883\tvalid_1's l1: 14.2365\n",
      "--- 201.75604367256165 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.66806\tvalid_1's l1: 14.7894\n",
      "[3000]\ttraining's l1: 8.29004\tvalid_1's l1: 14.1792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.29004\tvalid_1's l1: 14.1792\n",
      "--- 200.95917677879333 seconds ---\n",
      "1967\n",
      "mae on 11/29  :555807.8125850016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.15676974026019883, 'feature_fraction': 0.7927487835938299, 'lambda_l1': 0.11409427650561034, 'lambda_l2': 0.014722673213454471, 'bagging_fraction': 0.5224618808386622, 'bagging_freq': 30, 'max_bin': 151, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.10488\tvalid_1's l1: 15.2198\n",
      "[3000]\ttraining's l1: 7.74575\tvalid_1's l1: 14.742\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 7.74575\tvalid_1's l1: 14.742\n",
      "--- 183.54184532165527 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.26539\tvalid_1's l1: 15.2058\n",
      "[3000]\ttraining's l1: 7.82574\tvalid_1's l1: 14.7162\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 7.82574\tvalid_1's l1: 14.7162\n",
      "--- 184.82056713104248 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.19843\tvalid_1's l1: 15.0751\n",
      "[3000]\ttraining's l1: 7.70447\tvalid_1's l1: 14.5814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 7.70447\tvalid_1's l1: 14.5814\n",
      "--- 185.4964416027069 seconds ---\n",
      "1967\n",
      "mae on 11/29  :584828.2186758694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.10621400025738505, 'feature_fraction': 0.7094221857182454, 'lambda_l1': 0.036253899987609764, 'lambda_l2': 0.11784433030328305, 'bagging_fraction': 0.7889736643867177, 'bagging_freq': 85, 'max_bin': 109, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.36312\tvalid_1's l1: 14.8154\n",
      "[3000]\ttraining's l1: 8.0887\tvalid_1's l1: 14.2788\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.0887\tvalid_1's l1: 14.2788\n",
      "--- 193.60125374794006 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.51646\tvalid_1's l1: 14.8159\n",
      "[3000]\ttraining's l1: 8.23494\tvalid_1's l1: 14.2624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.23494\tvalid_1's l1: 14.2624\n",
      "--- 193.26774621009827 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.45254\tvalid_1's l1: 14.6652\n",
      "[3000]\ttraining's l1: 8.10398\tvalid_1's l1: 14.0906\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.10398\tvalid_1's l1: 14.0906\n",
      "--- 198.84759306907654 seconds ---\n",
      "1967\n",
      "mae on 11/29  :566419.430556394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.17076975072481476, 'feature_fraction': 0.7121618107680755, 'lambda_l1': 0.08118999435120097, 'lambda_l2': 0.15705337803667924, 'bagging_fraction': 0.7921908769170066, 'bagging_freq': 68, 'max_bin': 175, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 8.73891\tvalid_1's l1: 14.809\n",
      "[3000]\ttraining's l1: 7.6291\tvalid_1's l1: 14.4078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 7.6291\tvalid_1's l1: 14.4078\n",
      "--- 198.89309430122375 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 8.79832\tvalid_1's l1: 14.6762\n",
      "[3000]\ttraining's l1: 7.60514\tvalid_1's l1: 14.2009\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 7.60514\tvalid_1's l1: 14.2009\n",
      "--- 197.6138617992401 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 8.82293\tvalid_1's l1: 14.6517\n",
      "[3000]\ttraining's l1: 7.72989\tvalid_1's l1: 14.2303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 7.72989\tvalid_1's l1: 14.2303\n",
      "--- 195.8880033493042 seconds ---\n",
      "1967\n",
      "mae on 11/29  :560987.8288577216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.15621336355425158, 'feature_fraction': 0.7990417978494787, 'lambda_l1': 0.13997764153058076, 'lambda_l2': 0.15706856215556883, 'bagging_fraction': 0.5510346435271056, 'bagging_freq': 74, 'max_bin': 148, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.37325\tvalid_1's l1: 15.2715\n",
      "[3000]\ttraining's l1: 8.01934\tvalid_1's l1: 14.7959\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.01934\tvalid_1's l1: 14.7959\n",
      "--- 180.7692358493805 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.57304\tvalid_1's l1: 15.3776\n",
      "[3000]\ttraining's l1: 8.14167\tvalid_1's l1: 14.8681\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.14167\tvalid_1's l1: 14.8681\n",
      "--- 178.32317280769348 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.41336\tvalid_1's l1: 15.0894\n",
      "[3000]\ttraining's l1: 8.04542\tvalid_1's l1: 14.6298\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.04542\tvalid_1's l1: 14.6298\n",
      "--- 180.16769242286682 seconds ---\n",
      "1967\n",
      "mae on 11/29  :577875.0866106324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.1609988647127048, 'feature_fraction': 0.7208313114754651, 'lambda_l1': 0.11343401967624266, 'lambda_l2': 0.0337278499071973, 'bagging_fraction': 0.470438860535487, 'bagging_freq': 71, 'max_bin': 179, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.7968\tvalid_1's l1: 15.6773\n",
      "[3000]\ttraining's l1: 8.27343\tvalid_1's l1: 15.1857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.27343\tvalid_1's l1: 15.1857\n",
      "--- 169.18260550498962 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.77053\tvalid_1's l1: 15.5925\n",
      "[3000]\ttraining's l1: 8.29032\tvalid_1's l1: 15.1052\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.29032\tvalid_1's l1: 15.1052\n",
      "--- 167.78093886375427 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 9.80013\tvalid_1's l1: 15.4242\n",
      "[3000]\ttraining's l1: 8.22244\tvalid_1's l1: 14.9021\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 8.22244\tvalid_1's l1: 14.9021\n",
      "--- 171.54113936424255 seconds ---\n",
      "1967\n",
      "mae on 11/29  :591265.0554541679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0820\n",
    "default_parameters = [10, 0.1, 0.8, 0.06, 0.1, 0.8 , 30, 128 ,'121' ]\n",
    "\n",
    "n_calls = 20\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls = n_calls,\n",
    "                     random_state = RANDOM_STATE,\n",
    "                     x0=default_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf4yhFhqTWgI"
   },
   "outputs": [],
   "source": [
    "report = pd.concat([pd.DataFrame(res_gp.x_iters, columns = \n",
    "                                 [\"max_depth\",\"learning rate\",\"feature_fraction\",\"lambda_l1\",\n",
    "                                  \"lambda_l2\",\"bagging_fraction\",\"bagging_freq\",\"max_bin\",\"data\"]),\n",
    "            (pd.Series(res_gp.func_vals, name=\"mae\"))], axis=1)\n",
    "report.to_csv('./report_lgb_skopt_0820.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1566287000010,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "YTYjheliT5Ea",
    "outputId": "1fca4a52-5ce6-46bf-b3e6-fe53c2e6d07f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>data</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>557695.580924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.809126</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.108331</td>\n",
       "      <td>0.734642</td>\n",
       "      <td>46</td>\n",
       "      <td>232</td>\n",
       "      <td>121</td>\n",
       "      <td>600922.540323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.173703</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.714968</td>\n",
       "      <td>88</td>\n",
       "      <td>122</td>\n",
       "      <td>full</td>\n",
       "      <td>601256.559281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.821212</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.146586</td>\n",
       "      <td>0.605669</td>\n",
       "      <td>68</td>\n",
       "      <td>132</td>\n",
       "      <td>full</td>\n",
       "      <td>574533.498090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.060485</td>\n",
       "      <td>0.703002</td>\n",
       "      <td>0.159119</td>\n",
       "      <td>0.097655</td>\n",
       "      <td>0.336710</td>\n",
       "      <td>59</td>\n",
       "      <td>197</td>\n",
       "      <td>121</td>\n",
       "      <td>612468.292379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.065513</td>\n",
       "      <td>0.847109</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.123538</td>\n",
       "      <td>0.608719</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>121</td>\n",
       "      <td>589026.256646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.174109</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.129104</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.477329</td>\n",
       "      <td>96</td>\n",
       "      <td>151</td>\n",
       "      <td>121</td>\n",
       "      <td>582939.735980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.078035</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>0.724319</td>\n",
       "      <td>44</td>\n",
       "      <td>122</td>\n",
       "      <td>full</td>\n",
       "      <td>602596.283010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.223667</td>\n",
       "      <td>0.796909</td>\n",
       "      <td>0.163224</td>\n",
       "      <td>0.065823</td>\n",
       "      <td>0.878930</td>\n",
       "      <td>39</td>\n",
       "      <td>225</td>\n",
       "      <td>full</td>\n",
       "      <td>607588.112227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.061252</td>\n",
       "      <td>0.796260</td>\n",
       "      <td>0.126014</td>\n",
       "      <td>0.175829</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>28</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>597177.726228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.732289</td>\n",
       "      <td>0.091548</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>0.561761</td>\n",
       "      <td>52</td>\n",
       "      <td>131</td>\n",
       "      <td>full</td>\n",
       "      <td>593625.988240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0.090366</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.055875</td>\n",
       "      <td>0.044986</td>\n",
       "      <td>0.814566</td>\n",
       "      <td>99</td>\n",
       "      <td>135</td>\n",
       "      <td>full</td>\n",
       "      <td>591418.680482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.156083</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.115427</td>\n",
       "      <td>0.154161</td>\n",
       "      <td>0.523813</td>\n",
       "      <td>78</td>\n",
       "      <td>149</td>\n",
       "      <td>121</td>\n",
       "      <td>574554.587717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>0.065512</td>\n",
       "      <td>0.870409</td>\n",
       "      <td>0.177842</td>\n",
       "      <td>0.033017</td>\n",
       "      <td>0.608731</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>121</td>\n",
       "      <td>580320.264955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.717240</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.158094</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>65</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>555807.812585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.156770</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>0.114094</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>30</td>\n",
       "      <td>151</td>\n",
       "      <td>121</td>\n",
       "      <td>584828.218676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.106214</td>\n",
       "      <td>0.709422</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>0.117844</td>\n",
       "      <td>0.788974</td>\n",
       "      <td>85</td>\n",
       "      <td>109</td>\n",
       "      <td>121</td>\n",
       "      <td>566419.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.170770</td>\n",
       "      <td>0.712162</td>\n",
       "      <td>0.081190</td>\n",
       "      <td>0.157053</td>\n",
       "      <td>0.792191</td>\n",
       "      <td>68</td>\n",
       "      <td>175</td>\n",
       "      <td>121</td>\n",
       "      <td>560987.828858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.156213</td>\n",
       "      <td>0.799042</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>0.157069</td>\n",
       "      <td>0.551035</td>\n",
       "      <td>74</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>577875.086611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.720831</td>\n",
       "      <td>0.113434</td>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.470439</td>\n",
       "      <td>71</td>\n",
       "      <td>179</td>\n",
       "      <td>121</td>\n",
       "      <td>591265.055454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  learning rate  feature_fraction  ...  max_bin  data            mae\n",
       "0          10       0.100000          0.800000  ...      128   121  557695.580924\n",
       "1           8       0.116147          0.809126  ...      232   121  600922.540323\n",
       "2           8       0.103753          0.709824  ...      122  full  601256.559281\n",
       "3          11       0.108593          0.821212  ...      132  full  574533.498090\n",
       "4          10       0.060485          0.703002  ...      197   121  612468.292379\n",
       "5           9       0.065513          0.847109  ...       91   121  589026.256646\n",
       "6          10       0.174109          0.705303  ...      151   121  582939.735980\n",
       "7           8       0.078035          0.827387  ...      122  full  602596.283010\n",
       "8           8       0.223667          0.796909  ...      225  full  607588.112227\n",
       "9           9       0.061252          0.796260  ...      148   121  597177.726228\n",
       "10          9       0.198418          0.732289  ...      131  full  593625.988240\n",
       "11         10       0.090366          0.797927  ...      135  full  591418.680482\n",
       "12         10       0.156083          0.707865  ...      149   121  574554.587717\n",
       "13          9       0.065512          0.870409  ...       91   121  580320.264955\n",
       "14         10       0.100000          0.717240  ...      128   121  555807.812585\n",
       "15         10       0.156770          0.792749  ...      151   121  584828.218676\n",
       "16         10       0.106214          0.709422  ...      109   121  566419.430556\n",
       "17         10       0.170770          0.712162  ...      175   121  560987.828858\n",
       "18         10       0.156213          0.799042  ...      148   121  577875.086611\n",
       "19         10       0.160999          0.720831  ...      179   121  591265.055454\n",
       "\n",
       "[20 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9NmDkuR-ziG"
   },
   "outputs": [],
   "source": [
    "def objective(values):\n",
    "    params = {\n",
    "              'max_depth': values[0],  # 0\n",
    "              'task': 'train',\n",
    "              'num_leaves': int((2**(values[0]) ) -1) , \n",
    "              'learning_rate': values[1],    # 1\n",
    "              'feature_fraction': values[2], # 2\n",
    "              'lambda_l1': values[3],       # 3\n",
    "              'lambda_l2': values[4],         # 4\n",
    "              'bagging_fraction': values[5], # 5\n",
    "              'bagging_freq': values[6],       #  6\n",
    "              'max_bin': values[7],           # 7\n",
    "              'metric':'mae',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'objective': 'regression_l1',\n",
    "              'verbose': -1,\n",
    "              'seed': RANDOM_STATE\n",
    "              }\n",
    "\n",
    "    print('\\nNext set of params.....',params)\n",
    "    print(\"with data:   \"+values[8])\n",
    "    if values[8] == 'full':\n",
    "        resampled = resampled_existing_full.copy()\n",
    "    elif values[8] =='121':\n",
    "        resampled = resampled_existing_121.copy()\n",
    "\n",
    "    \n",
    "    real_train = resampled[resampled['date'] <= pd.to_datetime('2018-11-28') ]\n",
    "    real_test = resampled[(resampled['Year'] == 2018) &\n",
    "                          (resampled['Month'] == 11) &\n",
    "                          (resampled['Day'] == 29) ]\n",
    "\n",
    "    ##    \n",
    "    original_target = real_train.y.values\n",
    "    target, lambda_prophet = stats.boxcox(real_train['y'] + 1)\n",
    "    len_train=target.shape[0]\n",
    "    merged_df = pd.concat([real_train, real_test])\n",
    "    merged_df.drop(['y','date'],axis=1,inplace=True)\n",
    "\n",
    "    cate = ['store_id',  'Month', 'Week', 'Day', 'Dayofweek','Dayofyear', \n",
    "            'weekofyear','type_bus', 'high_region', 'full_region','cur_zero',\n",
    "            'cycle_idx_week1', 'cycle_idx_week2', 'cycle_idx_week4']\n",
    "\n",
    "    columns = merged_df.columns.values\n",
    "    col_dict = {}\n",
    "    for i,colname in enumerate(columns):\n",
    "        col_dict[colname] = i\n",
    "    cate_feat2num = [col_dict[colname] for colname in cate]\n",
    "\n",
    "    # do the training\n",
    "    num_folds = 3\n",
    "    test_x = merged_df[len_train:].values\n",
    "    all_x = merged_df[:len_train].values\n",
    "    all_y = target # removing what we did earlier\n",
    "    oof_preds = np.zeros([all_y.shape[0]])\n",
    "    sub_preds = np.zeros([test_x.shape[0]])\n",
    "    folds = KFold(n_splits=num_folds, shuffle=True, random_state=2019)\n",
    "    ##\n",
    "    num_boost_round = 3000\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(all_x)):\n",
    "        start_time = time.time()\n",
    "        train_x, train_y = all_x[train_idx], all_y[train_idx]\n",
    "        valid_x, valid_y = all_x[valid_idx], all_y[valid_idx]\n",
    "        lgb_train = lgb.Dataset(train_x,train_y)\n",
    "        lgb_valid = lgb.Dataset(valid_x,valid_y)\n",
    "\n",
    "        # train\n",
    "\n",
    "        gbm = lgb.train(params, lgb_train, num_boost_round= num_boost_round, \n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            early_stopping_rounds=100, verbose_eval=1500)\n",
    "        \n",
    "        oof_preds[valid_idx] = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "        sub_preds[:] += gbm.predict(test_x, num_iteration=gbm.best_iteration) / folds.n_splits\n",
    "        valid_idx += 1\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    sub_preds = inverse_boxcox(sub_preds , lambda_prophet) - 1\n",
    "    oof_preds = inverse_boxcox(oof_preds , lambda_prophet) - 1\n",
    "    y_true = real_test['y'].values\n",
    "\n",
    "    sub_preds = np.nan_to_num(sub_preds)\n",
    "    mae_1129 = mean_absolute_error(y_true = y_true, y_pred= sub_preds )\n",
    "    \n",
    "\n",
    "    print(len(y_true))\n",
    "    print(\"mae on 11/29  :\"+ str(mae_1129) )\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return mae_1129\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3tg1QH8-zZF"
   },
   "outputs": [],
   "source": [
    "space  = [Integer(8, 12, name='max_depth'), # 0\n",
    "          Real(0.05, 0.25,  name='learning_rate',prior='log-uniform',), # 1\n",
    "          Real(0.7, 0.9, name='feature_fraction'), # 2\n",
    "          Real(0.01, 0.2,  name='lambda_l1'), # 3\n",
    "          Real(0.01, 0.2,  name='lambda_l2'), # 4\n",
    "          Real(0.3, 0.9,  name='bagging_fraction'), # 5\n",
    "          Integer(5, 100, name='bagging_freq'), # 6\n",
    "          Integer(50, 255, name='max_bin'), #7\n",
    "          Categorical(['full','121'], name='data') # 8\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8171247,
     "status": "ok",
     "timestamp": 1566303017331,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "QT4v-6Uw-zGu",
    "outputId": "5e20d401-943a-43ad-fb76-511046d26fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'lambda_l1': 0.06, 'lambda_l2': 0.1, 'bagging_fraction': 0.8, 'bagging_freq': 30, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.812079\tvalid_1's l1: 1.32604\n",
      "[3000]\ttraining's l1: 0.701364\tvalid_1's l1: 1.28319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.701364\tvalid_1's l1: 1.28319\n",
      "--- 192.3959081172943 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.791352\tvalid_1's l1: 1.30737\n",
      "[3000]\ttraining's l1: 0.690739\tvalid_1's l1: 1.26983\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.690739\tvalid_1's l1: 1.26983\n",
      "--- 192.53298091888428 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.816181\tvalid_1's l1: 1.32048\n",
      "[3000]\ttraining's l1: 0.703333\tvalid_1's l1: 1.2791\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.703333\tvalid_1's l1: 1.2791\n",
      "--- 192.60733437538147 seconds ---\n",
      "1884\n",
      "mae on 11/29  :560240.9332050744\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.11614746341176702, 'feature_fraction': 0.8091264808742366, 'lambda_l1': 0.10647214537333566, 'lambda_l2': 0.1083314750853381, 'bagging_fraction': 0.7346420453587098, 'bagging_freq': 46, 'max_bin': 232, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.00906\tvalid_1's l1: 1.40464\n",
      "[3000]\ttraining's l1: 0.890339\tvalid_1's l1: 1.35875\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.890339\tvalid_1's l1: 1.35875\n",
      "--- 143.99507355690002 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.99821\tvalid_1's l1: 1.39301\n",
      "[3000]\ttraining's l1: 0.884428\tvalid_1's l1: 1.34963\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.884428\tvalid_1's l1: 1.34963\n",
      "--- 143.93718457221985 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.00869\tvalid_1's l1: 1.40381\n",
      "[3000]\ttraining's l1: 0.89144\tvalid_1's l1: 1.35891\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.89144\tvalid_1's l1: 1.35891\n",
      "--- 143.47483158111572 seconds ---\n",
      "1884\n",
      "mae on 11/29  :583049.148877245\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.10375278015379787, 'feature_fraction': 0.7098239111346972, 'lambda_l1': 0.17370340890400707, 'lambda_l2': 0.03314958183624209, 'bagging_fraction': 0.7149684145363726, 'bagging_freq': 88, 'max_bin': 122, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.05534\tvalid_1's l1: 1.42123\n",
      "[3000]\ttraining's l1: 0.947306\tvalid_1's l1: 1.37895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.947306\tvalid_1's l1: 1.37895\n",
      "--- 131.79121446609497 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.04351\tvalid_1's l1: 1.41451\n",
      "[3000]\ttraining's l1: 0.920024\tvalid_1's l1: 1.36726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.920024\tvalid_1's l1: 1.36726\n",
      "--- 131.1912763118744 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.02905\tvalid_1's l1: 1.40968\n",
      "[3000]\ttraining's l1: 0.918931\tvalid_1's l1: 1.36868\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.918931\tvalid_1's l1: 1.36868\n",
      "--- 136.19946575164795 seconds ---\n",
      "1884\n",
      "mae on 11/29  :590305.7166529597\n",
      "\n",
      "Next set of params..... {'max_depth': 11, 'task': 'train', 'num_leaves': 2047, 'learning_rate': 0.10859301111949785, 'feature_fraction': 0.8212123611246073, 'lambda_l1': 0.019668761840937302, 'lambda_l2': 0.14658569312890998, 'bagging_fraction': 0.6056686991154395, 'bagging_freq': 68, 'max_bin': 132, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.804522\tvalid_1's l1: 1.35661\n",
      "[3000]\ttraining's l1: 0.686919\tvalid_1's l1: 1.31768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.686919\tvalid_1's l1: 1.31768\n",
      "--- 216.40676736831665 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.769503\tvalid_1's l1: 1.33453\n",
      "[3000]\ttraining's l1: 0.658319\tvalid_1's l1: 1.30106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.658319\tvalid_1's l1: 1.30106\n",
      "--- 219.44136929512024 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.770101\tvalid_1's l1: 1.34421\n",
      "[3000]\ttraining's l1: 0.665454\tvalid_1's l1: 1.3117\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.665454\tvalid_1's l1: 1.3117\n",
      "--- 219.42164421081543 seconds ---\n",
      "1884\n",
      "mae on 11/29  :574826.5629176449\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.06048543582002651, 'feature_fraction': 0.7030021517045607, 'lambda_l1': 0.15911899312781935, 'lambda_l2': 0.09765537301931193, 'bagging_fraction': 0.3367098250074593, 'bagging_freq': 59, 'max_bin': 197, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.02302\tvalid_1's l1: 1.43605\n",
      "[3000]\ttraining's l1: 0.866983\tvalid_1's l1: 1.38504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.866983\tvalid_1's l1: 1.38504\n",
      "--- 150.2414674758911 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.01925\tvalid_1's l1: 1.43103\n",
      "[3000]\ttraining's l1: 0.853634\tvalid_1's l1: 1.37932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.853634\tvalid_1's l1: 1.37932\n",
      "--- 151.46582317352295 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.0267\tvalid_1's l1: 1.44097\n",
      "[3000]\ttraining's l1: 0.867654\tvalid_1's l1: 1.389\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.867654\tvalid_1's l1: 1.389\n",
      "--- 148.18564128875732 seconds ---\n",
      "1884\n",
      "mae on 11/29  :607556.285884743\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.0655128916989167, 'feature_fraction': 0.8471088324337869, 'lambda_l1': 0.17784017531463467, 'lambda_l2': 0.12353797501366898, 'bagging_fraction': 0.6087191577575439, 'bagging_freq': 61, 'max_bin': 91, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.992451\tvalid_1's l1: 1.39013\n",
      "[3000]\ttraining's l1: 0.861455\tvalid_1's l1: 1.34058\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.861455\tvalid_1's l1: 1.34058\n",
      "--- 143.69983959197998 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.981474\tvalid_1's l1: 1.37814\n",
      "[3000]\ttraining's l1: 0.853935\tvalid_1's l1: 1.33028\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.853935\tvalid_1's l1: 1.33028\n",
      "--- 145.08298182487488 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.990251\tvalid_1's l1: 1.39127\n",
      "[3000]\ttraining's l1: 0.859144\tvalid_1's l1: 1.34194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.859144\tvalid_1's l1: 1.34194\n",
      "--- 146.22062969207764 seconds ---\n",
      "1884\n",
      "mae on 11/29  :575640.5985107339\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.17410917265597495, 'feature_fraction': 0.7053025448039538, 'lambda_l1': 0.1291039037994003, 'lambda_l2': 0.03621953677058266, 'bagging_fraction': 0.47732892166011875, 'bagging_freq': 96, 'max_bin': 151, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.814624\tvalid_1's l1: 1.39284\n",
      "[3000]\ttraining's l1: 0.674336\tvalid_1's l1: 1.35708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.674336\tvalid_1's l1: 1.35708\n",
      "--- 143.03328943252563 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.817531\tvalid_1's l1: 1.39415\n",
      "[3000]\ttraining's l1: 0.680139\tvalid_1's l1: 1.3592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.680139\tvalid_1's l1: 1.3592\n",
      "--- 141.4203917980194 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.812707\tvalid_1's l1: 1.39664\n",
      "[3000]\ttraining's l1: 0.679099\tvalid_1's l1: 1.36033\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.679099\tvalid_1's l1: 1.36033\n",
      "--- 141.69105863571167 seconds ---\n",
      "1884\n",
      "mae on 11/29  :594637.1822591944\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.07803489145727022, 'feature_fraction': 0.8273867499483304, 'lambda_l1': 0.08496231118651096, 'lambda_l2': 0.15995271791649995, 'bagging_fraction': 0.72431869560092, 'bagging_freq': 44, 'max_bin': 122, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.07589\tvalid_1's l1: 1.42088\n",
      "[3000]\ttraining's l1: 0.97001\tvalid_1's l1: 1.37932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.97001\tvalid_1's l1: 1.37932\n",
      "--- 148.70478129386902 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.07059\tvalid_1's l1: 1.41998\n",
      "[3000]\ttraining's l1: 0.956503\tvalid_1's l1: 1.37748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.956503\tvalid_1's l1: 1.37748\n",
      "--- 150.2009346485138 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.08331\tvalid_1's l1: 1.43136\n",
      "[3000]\ttraining's l1: 0.971022\tvalid_1's l1: 1.38794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.971022\tvalid_1's l1: 1.38794\n",
      "--- 149.50737190246582 seconds ---\n",
      "1884\n",
      "mae on 11/29  :596856.1667119398\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'task': 'train', 'num_leaves': 255, 'learning_rate': 0.22366668275112497, 'feature_fraction': 0.7969092381772256, 'lambda_l1': 0.1632238480818866, 'lambda_l2': 0.0658230234124877, 'bagging_fraction': 0.8789297808569481, 'bagging_freq': 39, 'max_bin': 225, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.936724\tvalid_1's l1: 1.38721\n",
      "[3000]\ttraining's l1: 0.854461\tvalid_1's l1: 1.35916\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.854461\tvalid_1's l1: 1.35916\n",
      "--- 150.81643080711365 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.936282\tvalid_1's l1: 1.38905\n",
      "[3000]\ttraining's l1: 0.863544\tvalid_1's l1: 1.36355\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.863544\tvalid_1's l1: 1.36355\n",
      "--- 147.87014293670654 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.935376\tvalid_1's l1: 1.38393\n",
      "[3000]\ttraining's l1: 0.854961\tvalid_1's l1: 1.35702\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.854961\tvalid_1's l1: 1.35702\n",
      "--- 151.2525815963745 seconds ---\n",
      "1884\n",
      "mae on 11/29  :588496.3382880507\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.06125233786542991, 'feature_fraction': 0.7962601330218323, 'lambda_l1': 0.12601360113650834, 'lambda_l2': 0.1758294253664974, 'bagging_fraction': 0.4712820517500648, 'bagging_freq': 28, 'max_bin': 148, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.026\tvalid_1's l1: 1.41663\n",
      "[3000]\ttraining's l1: 0.885524\tvalid_1's l1: 1.36716\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.885524\tvalid_1's l1: 1.36716\n",
      "--- 144.22927927970886 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.01283\tvalid_1's l1: 1.40109\n",
      "[3000]\ttraining's l1: 0.871973\tvalid_1's l1: 1.3539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.871973\tvalid_1's l1: 1.3539\n",
      "--- 146.1632740497589 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 1.04015\tvalid_1's l1: 1.42496\n",
      "[3000]\ttraining's l1: 0.889387\tvalid_1's l1: 1.37324\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.889387\tvalid_1's l1: 1.37324\n",
      "--- 144.44032955169678 seconds ---\n",
      "1884\n",
      "mae on 11/29  :593728.5348890501\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.1984183089078719, 'feature_fraction': 0.7322894075268152, 'lambda_l1': 0.09154805216931897, 'lambda_l2': 0.042391222524376944, 'bagging_fraction': 0.5617605879645696, 'bagging_freq': 52, 'max_bin': 131, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   full\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.861867\tvalid_1's l1: 1.39659\n",
      "[3000]\ttraining's l1: 0.744787\tvalid_1's l1: 1.36386\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.744787\tvalid_1's l1: 1.36386\n",
      "--- 138.5303008556366 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.873474\tvalid_1's l1: 1.40433\n",
      "[3000]\ttraining's l1: 0.750022\tvalid_1's l1: 1.36933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.750022\tvalid_1's l1: 1.36933\n",
      "--- 135.6406171321869 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.87848\tvalid_1's l1: 1.4112\n",
      "[3000]\ttraining's l1: 0.751329\tvalid_1's l1: 1.37493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.751329\tvalid_1's l1: 1.37493\n",
      "--- 137.08923959732056 seconds ---\n",
      "1884\n",
      "mae on 11/29  :585639.3117633696\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.09770829362488219, 'feature_fraction': 0.7775764832172635, 'lambda_l1': 0.06723299058605614, 'lambda_l2': 0.08545807540254843, 'bagging_fraction': 0.7521095350867972, 'bagging_freq': 40, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.824073\tvalid_1's l1: 1.32764\n",
      "[3000]\ttraining's l1: 0.711688\tvalid_1's l1: 1.28542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.711688\tvalid_1's l1: 1.28542\n",
      "--- 182.08077478408813 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.818085\tvalid_1's l1: 1.32524\n",
      "[3000]\ttraining's l1: 0.701182\tvalid_1's l1: 1.28247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.701182\tvalid_1's l1: 1.28247\n",
      "--- 183.05405020713806 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.826542\tvalid_1's l1: 1.32723\n",
      "[3000]\ttraining's l1: 0.709068\tvalid_1's l1: 1.28431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.709068\tvalid_1's l1: 1.28431\n",
      "--- 182.6122124195099 seconds ---\n",
      "1884\n",
      "mae on 11/29  :560733.5943289667\n",
      "\n",
      "Next set of params..... {'max_depth': 11, 'task': 'train', 'num_leaves': 2047, 'learning_rate': 0.09671528369477815, 'feature_fraction': 0.7732414366982313, 'lambda_l1': 0.07230096914127374, 'lambda_l2': 0.08882870567988956, 'bagging_fraction': 0.7741095703400093, 'bagging_freq': 35, 'max_bin': 124, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.744206\tvalid_1's l1: 1.3018\n",
      "[3000]\ttraining's l1: 0.633376\tvalid_1's l1: 1.26172\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.633376\tvalid_1's l1: 1.26172\n",
      "--- 222.23888182640076 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.73252\tvalid_1's l1: 1.29455\n",
      "[3000]\ttraining's l1: 0.62585\tvalid_1's l1: 1.25551\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.62585\tvalid_1's l1: 1.25551\n",
      "--- 220.99725079536438 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.749089\tvalid_1's l1: 1.30968\n",
      "[3000]\ttraining's l1: 0.642192\tvalid_1's l1: 1.2713\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.642192\tvalid_1's l1: 1.2713\n",
      "--- 219.91657900810242 seconds ---\n",
      "1884\n",
      "mae on 11/29  :556869.919455255\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.10704840661112795, 'feature_fraction': 0.7926766862913037, 'lambda_l1': 0.07458391614531515, 'lambda_l2': 0.09164163212156833, 'bagging_fraction': 0.7771381172302296, 'bagging_freq': 48, 'max_bin': 56, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.887771\tvalid_1's l1: 1.33573\n",
      "[3000]\ttraining's l1: 0.772611\tvalid_1's l1: 1.29039\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.772611\tvalid_1's l1: 1.29039\n",
      "--- 140.9665822982788 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.867561\tvalid_1's l1: 1.32649\n",
      "[3000]\ttraining's l1: 0.76221\tvalid_1's l1: 1.28771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.76221\tvalid_1's l1: 1.28771\n",
      "--- 141.01268362998962 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.88371\tvalid_1's l1: 1.33405\n",
      "[3000]\ttraining's l1: 0.773443\tvalid_1's l1: 1.29311\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.773443\tvalid_1's l1: 1.29311\n",
      "--- 141.18211841583252 seconds ---\n",
      "1884\n",
      "mae on 11/29  :571978.966695003\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.11625471842097293, 'feature_fraction': 0.7528446875093155, 'lambda_l1': 0.07418683400068447, 'lambda_l2': 0.1554776014048235, 'bagging_fraction': 0.7361642404103346, 'bagging_freq': 56, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.791554\tvalid_1's l1: 1.32321\n",
      "[3000]\ttraining's l1: 0.682981\tvalid_1's l1: 1.28476\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.682981\tvalid_1's l1: 1.28476\n",
      "--- 177.17131280899048 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.783252\tvalid_1's l1: 1.31587\n",
      "[3000]\ttraining's l1: 0.679408\tvalid_1's l1: 1.27995\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.679408\tvalid_1's l1: 1.27995\n",
      "--- 174.42866253852844 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.79923\tvalid_1's l1: 1.33014\n",
      "[3000]\ttraining's l1: 0.689224\tvalid_1's l1: 1.29181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.689224\tvalid_1's l1: 1.29181\n",
      "--- 174.4033796787262 seconds ---\n",
      "1884\n",
      "mae on 11/29  :555315.1069168625\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.06660148694683997, 'feature_fraction': 0.8319658495725899, 'lambda_l1': 0.04679302574752979, 'lambda_l2': 0.10225034322759598, 'bagging_fraction': 0.7015751586622536, 'bagging_freq': 29, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.886658\tvalid_1's l1: 1.34706\n",
      "[3000]\ttraining's l1: 0.769796\tvalid_1's l1: 1.30372\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.769796\tvalid_1's l1: 1.30372\n",
      "--- 193.44293808937073 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.880492\tvalid_1's l1: 1.34232\n",
      "[3000]\ttraining's l1: 0.760132\tvalid_1's l1: 1.29837\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.760132\tvalid_1's l1: 1.29837\n",
      "--- 193.56761479377747 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.89646\tvalid_1's l1: 1.35624\n",
      "[3000]\ttraining's l1: 0.770771\tvalid_1's l1: 1.30828\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.770771\tvalid_1's l1: 1.30828\n",
      "--- 192.3444504737854 seconds ---\n",
      "1884\n",
      "mae on 11/29  :574105.6630853042\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.15078209829360545, 'feature_fraction': 0.7107031759763448, 'lambda_l1': 0.021155337069858865, 'lambda_l2': 0.1440169278815792, 'bagging_fraction': 0.829142024760521, 'bagging_freq': 37, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.739528\tvalid_1's l1: 1.30327\n",
      "[3000]\ttraining's l1: 0.639493\tvalid_1's l1: 1.26822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.639493\tvalid_1's l1: 1.26822\n",
      "--- 175.25273847579956 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.744738\tvalid_1's l1: 1.29813\n",
      "[3000]\ttraining's l1: 0.65661\tvalid_1's l1: 1.26927\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.65661\tvalid_1's l1: 1.26927\n",
      "--- 171.50386333465576 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.745748\tvalid_1's l1: 1.31306\n",
      "[3000]\ttraining's l1: 0.646004\tvalid_1's l1: 1.27783\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.646004\tvalid_1's l1: 1.27783\n",
      "--- 173.8940806388855 seconds ---\n",
      "1884\n",
      "mae on 11/29  :554685.8627164476\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.10340353149150165, 'feature_fraction': 0.7286464111487218, 'lambda_l1': 0.027048373221774315, 'lambda_l2': 0.1356169937697371, 'bagging_fraction': 0.6966733709084733, 'bagging_freq': 36, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.811621\tvalid_1's l1: 1.32677\n",
      "[3000]\ttraining's l1: 0.704588\tvalid_1's l1: 1.28964\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.704588\tvalid_1's l1: 1.28964\n",
      "--- 170.96560192108154 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.809402\tvalid_1's l1: 1.32726\n",
      "[3000]\ttraining's l1: 0.69802\tvalid_1's l1: 1.28904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.69802\tvalid_1's l1: 1.28904\n",
      "--- 170.95369410514832 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.830086\tvalid_1's l1: 1.34132\n",
      "[3000]\ttraining's l1: 0.710918\tvalid_1's l1: 1.30008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.710918\tvalid_1's l1: 1.30008\n",
      "--- 168.84674048423767 seconds ---\n",
      "1884\n",
      "mae on 11/29  :564728.0664222005\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.11357662072901809, 'feature_fraction': 0.7542209877357813, 'lambda_l1': 0.05046244505755697, 'lambda_l2': 0.12623114922176193, 'bagging_fraction': 0.7674713291318944, 'bagging_freq': 40, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.796571\tvalid_1's l1: 1.31968\n",
      "[3000]\ttraining's l1: 0.688162\tvalid_1's l1: 1.27977\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.688162\tvalid_1's l1: 1.27977\n",
      "--- 177.6257050037384 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.781495\tvalid_1's l1: 1.31313\n",
      "[3000]\ttraining's l1: 0.677082\tvalid_1's l1: 1.2763\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.677082\tvalid_1's l1: 1.2763\n",
      "--- 177.9359564781189 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.804207\tvalid_1's l1: 1.32943\n",
      "[3000]\ttraining's l1: 0.691284\tvalid_1's l1: 1.28822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.691284\tvalid_1's l1: 1.28822\n",
      "--- 176.69207739830017 seconds ---\n",
      "1884\n",
      "mae on 11/29  :564182.6274829487\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.09740229735009798, 'feature_fraction': 0.711336688904622, 'lambda_l1': 0.06700536861218284, 'lambda_l2': 0.1725966419556319, 'bagging_fraction': 0.4648399755653305, 'bagging_freq': 68, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.907547\tvalid_1's l1: 1.39327\n",
      "[3000]\ttraining's l1: 0.765966\tvalid_1's l1: 1.3508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.765966\tvalid_1's l1: 1.3508\n",
      "--- 141.70694136619568 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.88205\tvalid_1's l1: 1.38028\n",
      "[3000]\ttraining's l1: 0.741018\tvalid_1's l1: 1.33859\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.741018\tvalid_1's l1: 1.33859\n",
      "--- 143.59695506095886 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.886584\tvalid_1's l1: 1.38736\n",
      "[3000]\ttraining's l1: 0.752344\tvalid_1's l1: 1.34538\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.752344\tvalid_1's l1: 1.34538\n",
      "--- 141.857426404953 seconds ---\n",
      "1884\n",
      "mae on 11/29  :590887.7975521928\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.11701059582737426, 'feature_fraction': 0.7621303630103138, 'lambda_l1': 0.048061080641592424, 'lambda_l2': 0.11797662063613668, 'bagging_fraction': 0.8224449321503675, 'bagging_freq': 36, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.780728\tvalid_1's l1: 1.31444\n",
      "[3000]\ttraining's l1: 0.670839\tvalid_1's l1: 1.27171\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.670839\tvalid_1's l1: 1.27171\n",
      "--- 185.28566646575928 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.779202\tvalid_1's l1: 1.30397\n",
      "[3000]\ttraining's l1: 0.674831\tvalid_1's l1: 1.26529\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.674831\tvalid_1's l1: 1.26529\n",
      "--- 182.15510320663452 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.775586\tvalid_1's l1: 1.31211\n",
      "[3000]\ttraining's l1: 0.678656\tvalid_1's l1: 1.27702\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.678656\tvalid_1's l1: 1.27702\n",
      "--- 184.49179196357727 seconds ---\n",
      "1884\n",
      "mae on 11/29  :551690.056420414\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.11801003710933619, 'feature_fraction': 0.7629749485604209, 'lambda_l1': 0.04752275844216348, 'lambda_l2': 0.11771178068438871, 'bagging_fraction': 0.8333599018874871, 'bagging_freq': 35, 'max_bin': 128, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.771635\tvalid_1's l1: 1.30411\n",
      "[3000]\ttraining's l1: 0.669486\tvalid_1's l1: 1.26556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.669486\tvalid_1's l1: 1.26556\n",
      "--- 185.8833827972412 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.774849\tvalid_1's l1: 1.30729\n",
      "[3000]\ttraining's l1: 0.672957\tvalid_1's l1: 1.27043\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.672957\tvalid_1's l1: 1.27043\n",
      "--- 183.41244864463806 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.778147\tvalid_1's l1: 1.31425\n",
      "[3000]\ttraining's l1: 0.675136\tvalid_1's l1: 1.2746\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.675136\tvalid_1's l1: 1.2746\n",
      "--- 184.87817788124084 seconds ---\n",
      "1884\n",
      "mae on 11/29  :563630.0449532506\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.23569819435872985, 'feature_fraction': 0.7076859110196868, 'lambda_l1': 0.031304367070717744, 'lambda_l2': 0.17252427394078237, 'bagging_fraction': 0.7935504994826057, 'bagging_freq': 37, 'max_bin': 125, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.694971\tvalid_1's l1: 1.32066\n",
      "[3000]\ttraining's l1: 0.603715\tvalid_1's l1: 1.29475\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.603715\tvalid_1's l1: 1.29475\n",
      "--- 162.93460607528687 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.691441\tvalid_1's l1: 1.32316\n",
      "[3000]\ttraining's l1: 0.602735\tvalid_1's l1: 1.29793\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.602735\tvalid_1's l1: 1.29793\n",
      "--- 163.09442853927612 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.685744\tvalid_1's l1: 1.31954\n",
      "[3000]\ttraining's l1: 0.593165\tvalid_1's l1: 1.29166\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.593165\tvalid_1's l1: 1.29166\n",
      "--- 165.81714296340942 seconds ---\n",
      "1884\n",
      "mae on 11/29  :559044.915487541\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.1525202087713292, 'feature_fraction': 0.8349870427199397, 'lambda_l1': 0.029765922810770125, 'lambda_l2': 0.1324606931140578, 'bagging_fraction': 0.7978060580549209, 'bagging_freq': 93, 'max_bin': 120, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.757384\tvalid_1's l1: 1.30771\n",
      "[3000]\ttraining's l1: 0.657393\tvalid_1's l1: 1.27433\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.657393\tvalid_1's l1: 1.27433\n",
      "--- 179.6710376739502 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.744989\tvalid_1's l1: 1.31201\n",
      "[3000]\ttraining's l1: 0.654612\tvalid_1's l1: 1.28019\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.654612\tvalid_1's l1: 1.28019\n",
      "--- 177.48298001289368 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.76568\tvalid_1's l1: 1.32453\n",
      "[3000]\ttraining's l1: 0.66305\tvalid_1's l1: 1.28721\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.66305\tvalid_1's l1: 1.28721\n",
      "--- 178.35811233520508 seconds ---\n",
      "1884\n",
      "mae on 11/29  :564362.9342474017\n",
      "\n",
      "Next set of params..... {'max_depth': 12, 'task': 'train', 'num_leaves': 4095, 'learning_rate': 0.08664506097373662, 'feature_fraction': 0.8093846604567058, 'lambda_l1': 0.07410751203775216, 'lambda_l2': 0.08693680039990521, 'bagging_fraction': 0.7952029697857066, 'bagging_freq': 83, 'max_bin': 125, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.704706\tvalid_1's l1: 1.29671\n",
      "[3000]\ttraining's l1: 0.590404\tvalid_1's l1: 1.25265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.590404\tvalid_1's l1: 1.25265\n",
      "--- 272.64844703674316 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.689609\tvalid_1's l1: 1.29041\n",
      "[3000]\ttraining's l1: 0.586962\tvalid_1's l1: 1.2543\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.586962\tvalid_1's l1: 1.2543\n",
      "--- 273.1796507835388 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.682347\tvalid_1's l1: 1.28779\n",
      "[3000]\ttraining's l1: 0.591065\tvalid_1's l1: 1.25719\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.591065\tvalid_1's l1: 1.25719\n",
      "--- 270.8143541812897 seconds ---\n",
      "1884\n",
      "mae on 11/29  :551332.8933958573\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.08530018766077727, 'feature_fraction': 0.7990195539628625, 'lambda_l1': 0.10216643524736489, 'lambda_l2': 0.09002681246575046, 'bagging_fraction': 0.7961107795103087, 'bagging_freq': 24, 'max_bin': 125, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.824316\tvalid_1's l1: 1.32218\n",
      "[3000]\ttraining's l1: 0.713552\tvalid_1's l1: 1.27929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.713552\tvalid_1's l1: 1.27929\n",
      "--- 197.2760045528412 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.817648\tvalid_1's l1: 1.31382\n",
      "[3000]\ttraining's l1: 0.707389\tvalid_1's l1: 1.27369\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.707389\tvalid_1's l1: 1.27369\n",
      "--- 195.53093671798706 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.827886\tvalid_1's l1: 1.32552\n",
      "[3000]\ttraining's l1: 0.714834\tvalid_1's l1: 1.28155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.714834\tvalid_1's l1: 1.28155\n",
      "--- 196.7235734462738 seconds ---\n",
      "1884\n",
      "mae on 11/29  :568618.119345903\n",
      "\n",
      "Next set of params..... {'max_depth': 11, 'task': 'train', 'num_leaves': 2047, 'learning_rate': 0.09857645851842003, 'feature_fraction': 0.7658013145402657, 'lambda_l1': 0.11531318442147005, 'lambda_l2': 0.083674196123685, 'bagging_fraction': 0.7963104947502749, 'bagging_freq': 73, 'max_bin': 125, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.747695\tvalid_1's l1: 1.30241\n",
      "[3000]\ttraining's l1: 0.639526\tvalid_1's l1: 1.26461\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.639526\tvalid_1's l1: 1.26461\n",
      "--- 216.53531098365784 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.728201\tvalid_1's l1: 1.29441\n",
      "[3000]\ttraining's l1: 0.621649\tvalid_1's l1: 1.2558\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.621649\tvalid_1's l1: 1.2558\n",
      "--- 221.10119080543518 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.739553\tvalid_1's l1: 1.30308\n",
      "[3000]\ttraining's l1: 0.638388\tvalid_1's l1: 1.26654\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.638388\tvalid_1's l1: 1.26654\n",
      "--- 217.51984333992004 seconds ---\n",
      "1884\n",
      "mae on 11/29  :560468.4876370648\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.15652909994849942, 'feature_fraction': 0.7405462799384757, 'lambda_l1': 0.01822204279046569, 'lambda_l2': 0.17434927090406876, 'bagging_fraction': 0.7991407164922825, 'bagging_freq': 19, 'max_bin': 209, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.74114\tvalid_1's l1: 1.31204\n",
      "[3000]\ttraining's l1: 0.649468\tvalid_1's l1: 1.28164\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.649468\tvalid_1's l1: 1.28164\n",
      "--- 194.16570043563843 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.744074\tvalid_1's l1: 1.31141\n",
      "[3000]\ttraining's l1: 0.64597\tvalid_1's l1: 1.27822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.64597\tvalid_1's l1: 1.27822\n",
      "--- 191.09731435775757 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.753328\tvalid_1's l1: 1.31984\n",
      "[3000]\ttraining's l1: 0.655615\tvalid_1's l1: 1.28546\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.655615\tvalid_1's l1: 1.28546\n",
      "--- 192.9094250202179 seconds ---\n",
      "1884\n",
      "mae on 11/29  :567931.9251839622\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'task': 'train', 'num_leaves': 511, 'learning_rate': 0.09591940426662193, 'feature_fraction': 0.7546683723298692, 'lambda_l1': 0.10235253581807804, 'lambda_l2': 0.10242361693387492, 'bagging_fraction': 0.7979736317021284, 'bagging_freq': 50, 'max_bin': 125, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.912104\tvalid_1's l1: 1.35038\n",
      "[3000]\ttraining's l1: 0.798285\tvalid_1's l1: 1.30386\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.798285\tvalid_1's l1: 1.30386\n",
      "--- 152.77424931526184 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.909012\tvalid_1's l1: 1.34908\n",
      "[3000]\ttraining's l1: 0.796107\tvalid_1's l1: 1.30475\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.796107\tvalid_1's l1: 1.30475\n",
      "--- 153.08095526695251 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.907378\tvalid_1's l1: 1.35066\n",
      "[3000]\ttraining's l1: 0.794173\tvalid_1's l1: 1.30488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.794173\tvalid_1's l1: 1.30488\n",
      "--- 156.03933596611023 seconds ---\n",
      "1884\n",
      "mae on 11/29  :571357.8217087042\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'task': 'train', 'num_leaves': 1023, 'learning_rate': 0.0679804177192823, 'feature_fraction': 0.8531577815757294, 'lambda_l1': 0.0417866048820672, 'lambda_l2': 0.13485337240421003, 'bagging_fraction': 0.7980319757138343, 'bagging_freq': 30, 'max_bin': 125, 'metric': 'mae', 'boosting_type': 'gbdt', 'objective': 'regression_l1', 'verbose': -1, 'seed': 2019}\n",
      "with data:   121\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.861732\tvalid_1's l1: 1.33395\n",
      "[3000]\ttraining's l1: 0.753616\tvalid_1's l1: 1.29266\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.753616\tvalid_1's l1: 1.29266\n",
      "--- 206.730975151062 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.857556\tvalid_1's l1: 1.32604\n",
      "[3000]\ttraining's l1: 0.746596\tvalid_1's l1: 1.28422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.746596\tvalid_1's l1: 1.28422\n",
      "--- 205.26712942123413 seconds ---\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1500]\ttraining's l1: 0.867436\tvalid_1's l1: 1.33932\n",
      "[3000]\ttraining's l1: 0.755225\tvalid_1's l1: 1.29527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.755225\tvalid_1's l1: 1.29527\n",
      "--- 206.90757989883423 seconds ---\n",
      "1884\n",
      "mae on 11/29  :572187.2253781476\n"
     ]
    }
   ],
   "source": [
    "default_parameters = [10, 0.1, 0.8, 0.06, 0.1, 0.8 , 30, 128 ,'121' ]\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls = 30,\n",
    "                     random_state = RANDOM_STATE,\n",
    "                     x0=default_parameters)\n",
    "\n",
    "report = pd.concat([pd.DataFrame(res_gp.x_iters, columns = \n",
    "                                 [\"max_depth\",\"learning rate\",\"feature_fraction\",\"lambda_l1\",\n",
    "                                  \"lambda_l2\",\"bagging_fraction\",\"bagging_freq\",\"max_bin\",\"data\"]),\n",
    "            (pd.Series(res_gp.func_vals, name=\"mae\"))], axis=1)\n",
    "report.to_csv('./report_lgb_skopt_0820_existing.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1566303241154,
     "user": {
      "displayName": "남윤상",
      "photoUrl": "",
      "userId": "02917917479382069695"
     },
     "user_tz": -540
    },
    "id": "HQ-iEnAU-zBC",
    "outputId": "1639bf17-f69d-4d54-b7d8-8ce0ed9e3f16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>data</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.809385</td>\n",
       "      <td>0.074108</td>\n",
       "      <td>0.086937</td>\n",
       "      <td>0.795203</td>\n",
       "      <td>83</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>551332.893396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.117011</td>\n",
       "      <td>0.762130</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>0.117977</td>\n",
       "      <td>0.822445</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>551690.056420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.150782</td>\n",
       "      <td>0.710703</td>\n",
       "      <td>0.021155</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>0.829142</td>\n",
       "      <td>37</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>554685.862716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0.116255</td>\n",
       "      <td>0.752845</td>\n",
       "      <td>0.074187</td>\n",
       "      <td>0.155478</td>\n",
       "      <td>0.736164</td>\n",
       "      <td>56</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>555315.106917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.773241</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.774110</td>\n",
       "      <td>35</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>556869.919455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>0.235698</td>\n",
       "      <td>0.707686</td>\n",
       "      <td>0.031304</td>\n",
       "      <td>0.172524</td>\n",
       "      <td>0.793550</td>\n",
       "      <td>37</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>559044.915488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>560240.933205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11</td>\n",
       "      <td>0.098576</td>\n",
       "      <td>0.765801</td>\n",
       "      <td>0.115313</td>\n",
       "      <td>0.083674</td>\n",
       "      <td>0.796310</td>\n",
       "      <td>73</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>560468.487637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0.097708</td>\n",
       "      <td>0.777576</td>\n",
       "      <td>0.067233</td>\n",
       "      <td>0.085458</td>\n",
       "      <td>0.752110</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>560733.594329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.118010</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.047523</td>\n",
       "      <td>0.117712</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>563630.044953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.113577</td>\n",
       "      <td>0.754221</td>\n",
       "      <td>0.050462</td>\n",
       "      <td>0.126231</td>\n",
       "      <td>0.767471</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>564182.627483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>0.152520</td>\n",
       "      <td>0.834987</td>\n",
       "      <td>0.029766</td>\n",
       "      <td>0.132461</td>\n",
       "      <td>0.797806</td>\n",
       "      <td>93</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>564362.934247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.103404</td>\n",
       "      <td>0.728646</td>\n",
       "      <td>0.027048</td>\n",
       "      <td>0.135617</td>\n",
       "      <td>0.696673</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>564728.066422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>0.156529</td>\n",
       "      <td>0.740546</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.174349</td>\n",
       "      <td>0.799141</td>\n",
       "      <td>19</td>\n",
       "      <td>209</td>\n",
       "      <td>121</td>\n",
       "      <td>567931.925184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.799020</td>\n",
       "      <td>0.102166</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0.796111</td>\n",
       "      <td>24</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>568618.119346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>0.095919</td>\n",
       "      <td>0.754668</td>\n",
       "      <td>0.102353</td>\n",
       "      <td>0.102424</td>\n",
       "      <td>0.797974</td>\n",
       "      <td>50</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>571357.821709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>0.107048</td>\n",
       "      <td>0.792677</td>\n",
       "      <td>0.074584</td>\n",
       "      <td>0.091642</td>\n",
       "      <td>0.777138</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>121</td>\n",
       "      <td>571978.966695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>0.067980</td>\n",
       "      <td>0.853158</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0.134853</td>\n",
       "      <td>0.798032</td>\n",
       "      <td>30</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>572187.225378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.066601</td>\n",
       "      <td>0.831966</td>\n",
       "      <td>0.046793</td>\n",
       "      <td>0.102250</td>\n",
       "      <td>0.701575</td>\n",
       "      <td>29</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>574105.663085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.821212</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.146586</td>\n",
       "      <td>0.605669</td>\n",
       "      <td>68</td>\n",
       "      <td>132</td>\n",
       "      <td>full</td>\n",
       "      <td>574826.562918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.065513</td>\n",
       "      <td>0.847109</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.123538</td>\n",
       "      <td>0.608719</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>121</td>\n",
       "      <td>575640.598511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.809126</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.108331</td>\n",
       "      <td>0.734642</td>\n",
       "      <td>46</td>\n",
       "      <td>232</td>\n",
       "      <td>121</td>\n",
       "      <td>583049.148877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.732289</td>\n",
       "      <td>0.091548</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>0.561761</td>\n",
       "      <td>52</td>\n",
       "      <td>131</td>\n",
       "      <td>full</td>\n",
       "      <td>585639.311763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.223667</td>\n",
       "      <td>0.796909</td>\n",
       "      <td>0.163224</td>\n",
       "      <td>0.065823</td>\n",
       "      <td>0.878930</td>\n",
       "      <td>39</td>\n",
       "      <td>225</td>\n",
       "      <td>full</td>\n",
       "      <td>588496.338288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.173703</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.714968</td>\n",
       "      <td>88</td>\n",
       "      <td>122</td>\n",
       "      <td>full</td>\n",
       "      <td>590305.716653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.097402</td>\n",
       "      <td>0.711337</td>\n",
       "      <td>0.067005</td>\n",
       "      <td>0.172597</td>\n",
       "      <td>0.464840</td>\n",
       "      <td>68</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>590887.797552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.061252</td>\n",
       "      <td>0.796260</td>\n",
       "      <td>0.126014</td>\n",
       "      <td>0.175829</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>28</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>593728.534889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.174109</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.129104</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.477329</td>\n",
       "      <td>96</td>\n",
       "      <td>151</td>\n",
       "      <td>121</td>\n",
       "      <td>594637.182259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.078035</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>0.724319</td>\n",
       "      <td>44</td>\n",
       "      <td>122</td>\n",
       "      <td>full</td>\n",
       "      <td>596856.166712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.060485</td>\n",
       "      <td>0.703002</td>\n",
       "      <td>0.159119</td>\n",
       "      <td>0.097655</td>\n",
       "      <td>0.336710</td>\n",
       "      <td>59</td>\n",
       "      <td>197</td>\n",
       "      <td>121</td>\n",
       "      <td>607556.285885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  learning rate  feature_fraction  ...  max_bin  data            mae\n",
       "24         12       0.086645          0.809385  ...      125   121  551332.893396\n",
       "20         10       0.117011          0.762130  ...      128   121  551690.056420\n",
       "16         10       0.150782          0.710703  ...      128   121  554685.862716\n",
       "14         10       0.116255          0.752845  ...      128   121  555315.106917\n",
       "12         11       0.096715          0.773241  ...      124   121  556869.919455\n",
       "22         10       0.235698          0.707686  ...      125   121  559044.915488\n",
       "0          10       0.100000          0.800000  ...      128   121  560240.933205\n",
       "26         11       0.098576          0.765801  ...      125   121  560468.487637\n",
       "11         10       0.097708          0.777576  ...      128   121  560733.594329\n",
       "21         10       0.118010          0.762975  ...      128   121  563630.044953\n",
       "18         10       0.113577          0.754221  ...      128   121  564182.627483\n",
       "23         10       0.152520          0.834987  ...      120   121  564362.934247\n",
       "17         10       0.103404          0.728646  ...      128   121  564728.066422\n",
       "27         10       0.156529          0.740546  ...      209   121  567931.925184\n",
       "25         10       0.085300          0.799020  ...      125   121  568618.119346\n",
       "28          9       0.095919          0.754668  ...      125   121  571357.821709\n",
       "13          9       0.107048          0.792677  ...       56   121  571978.966695\n",
       "29         10       0.067980          0.853158  ...      125   121  572187.225378\n",
       "15         10       0.066601          0.831966  ...      128   121  574105.663085\n",
       "3          11       0.108593          0.821212  ...      132  full  574826.562918\n",
       "5           9       0.065513          0.847109  ...       91   121  575640.598511\n",
       "1           8       0.116147          0.809126  ...      232   121  583049.148877\n",
       "10          9       0.198418          0.732289  ...      131  full  585639.311763\n",
       "8           8       0.223667          0.796909  ...      225  full  588496.338288\n",
       "2           8       0.103753          0.709824  ...      122  full  590305.716653\n",
       "19         10       0.097402          0.711337  ...      128   121  590887.797552\n",
       "9           9       0.061252          0.796260  ...      148   121  593728.534889\n",
       "6          10       0.174109          0.705303  ...      151   121  594637.182259\n",
       "7           8       0.078035          0.827387  ...      122  full  596856.166712\n",
       "4          10       0.060485          0.703002  ...      197   121  607556.285885\n",
       "\n",
       "[30 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.sort_values('mae',ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7RSYdxlwEBz"
   },
   "source": [
    "- References:\n",
    "    - https://www.kaggle.com/a31314431/bayesian-optimization-lightgbm\n",
    "    - https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "    - https://zzsza.github.io/data/2018/09/03/how-to-win-a-data-science-competition-week4/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Lightgbm_skopt.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
